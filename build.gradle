/*
 * SPDX-License-Identifier: Apache-2.0
 *
 * The OpenSearch Contributors require contributions made to
 * this file be licensed under the Apache-2.0 license or a
 * compatible open source license.
 *
 * Modifications Copyright OpenSearch Contributors. See
 * GitHub history for details.
 */

import java.util.concurrent.Callable
import org.opensearch.gradle.test.RestIntegTestTask
import org.opensearch.gradle.testclusters.ExtensionsProperties
import org.opensearch.gradle.testclusters.StandaloneRestIntegTestTask

buildscript {
    ext {
        opensearch_group = "org.opensearch"
        isSnapshot = "true" == System.getProperty("build.snapshot", "true")
        opensearch_version = System.getProperty("opensearch.version", "3.0.0-SNAPSHOT")
        buildVersionQualifier = System.getProperty("build.version_qualifier", "")
        // 3.0.0-SNAPSHOT -> 3.0.0.0-SNAPSHOT
        version_tokens = opensearch_version.tokenize('-')
        opensearch_build = version_tokens[0] + '.0'
        plugin_no_snapshot = opensearch_build
        if (buildVersionQualifier) {
            opensearch_build += "-${buildVersionQualifier}"
            plugin_no_snapshot += "-${buildVersionQualifier}"
        }
        if (isSnapshot) {
            opensearch_build += "-SNAPSHOT"
        }
        opensearch_no_snapshot = opensearch_version.replace("-SNAPSHOT","")
        js_resource_folder = "src/test/resources/job-scheduler"
        common_utils_version = System.getProperty("common_utils.version", opensearch_build)
        job_scheduler_version = System.getProperty("job_scheduler.version", opensearch_build)
        job_scheduler_build_download = 'https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/' + opensearch_no_snapshot +
                '/latest/linux/x64/tar/builds/opensearch/plugins/opensearch-job-scheduler-' + plugin_no_snapshot + '.zip'
        bwcVersionShort = "2.6.0"
        bwcVersion = bwcVersionShort + ".0"
        bwcOpenSearchADDownload = 'https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/' + bwcVersionShort + '/latest/linux/x64/tar/builds/' +
                'opensearch/plugins/opensearch-anomaly-detection-' + bwcVersion + '.zip'
        bwcOpenSearchJSDownload = 'https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/' + bwcVersionShort + '/latest/linux/x64/tar/builds/' +
                'opensearch/plugins/opensearch-job-scheduler-' + bwcVersion + '.zip'
        baseName = "adBwcCluster"
        bwcFilePath = "src/test/resources/org/opensearch/ad/bwc/"
        bwcJobSchedulerPath = bwcFilePath + "job-scheduler/"
        bwcAnomalyDetectionPath = bwcFilePath + "anomaly-detection/"

        // gradle build won't print logs during test by default unless there is a failure.
        // It is useful to record intermediately information like prediction precision and recall.
        // This option turn on log printing during tests. 
        printLogs = "true" == System.getProperty("test.logs", "false")
    }

    repositories {
        mavenLocal()
        maven { url "https://aws.oss.sonatype.org/content/repositories/snapshots" }
        mavenCentral()
        maven { url "https://plugins.gradle.org/m2/" }
    }

    dependencies {
        classpath "${opensearch_group}.gradle:build-tools:${opensearch_version}"
    }
}

plugins {
    id 'java'
    id 'com.netflix.nebula.ospackage-base' version "11.0.0" apply false
    id "com.diffplug.spotless" version "6.18.0"
    id 'java-library'
    id 'org.gradle.test-retry' version '1.5.1'
}

tasks.withType(JavaCompile) {
    options.encoding = "UTF-8"
}
tasks.withType(Test) {
    systemProperty "file.encoding", "UTF-8"
    jvmArgs("--add-opens", "java.base/java.time=ALL-UNNAMED")
    jvmArgs("--add-opens", "java.base/java.util.stream=ALL-UNNAMED")
}
tasks.withType(Javadoc) {
    options.encoding = 'UTF-8'
}

repositories {
    mavenLocal()
    maven { url "https://aws.oss.sonatype.org/content/repositories/snapshots" }
    mavenCentral()
    maven { url "https://plugins.gradle.org/m2/" }
    maven { url "https://d1nvenhzbhpy0q.cloudfront.net/snapshots/lucene/" }
}

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'opensearch.opensearchplugin'
apply plugin: 'opensearch.testclusters'
apply plugin: 'base'
apply plugin: 'jacoco'
apply plugin: 'eclipse'
//apply plugin: 'opensearch.pluginzip'
apply plugin: 'maven-publish'

ext {
    isSnapshot = "true" == System.getProperty("build.snapshot", "true")
    buildVersionQualifier = System.getProperty("build.version_qualifier")
}

allprojects {
    group = 'org.opensearch'

    version = "${opensearch_build}"

    plugins.withId('java') {
        sourceCompatibility = targetCompatibility = JavaVersion.VERSION_11
    }
}

opensearchplugin {
    name 'opensearch-anomaly-detection'
    description 'OpenSearch anomaly detector plugin'
    classname 'org.opensearch.ad.AnomalyDetectorExtension'
    extendedPlugins = ['lang-painless', 'opensearch-job-scheduler']
}

ext {
    projectSubstitutions = [:]
    licenseFile = rootProject.file('LICENSE.txt')
    noticeFile = rootProject.file('NOTICE.txt')
}

// Handle case where older versions of esplugin doesn't expose the joda time version it uses
configurations.all {
    if (it.state != Configuration.State.UNRESOLVED) return
    resolutionStrategy {
        force "joda-time:joda-time:2.10.13"
        force "commons-logging:commons-logging:1.2"
        force "org.apache.httpcomponents:httpcore5:5.1.4"
        force "commons-codec:commons-codec:1.15"

        force "org.mockito:mockito-core:2.25.0"
        force "org.objenesis:objenesis:3.0.1"
        force "net.bytebuddy:byte-buddy:1.9.15"
        force "net.bytebuddy:byte-buddy-agent:1.9.15"
        force "com.google.code.gson:gson:2.8.9"
        force "junit:junit:4.13.2"

        force "jakarta.json:jakarta.json-api:2.1.1"
        force "com.google.guava:guava:31.1-jre"
        force "org.apache.logging.log4j:log4j-api:2.20.0"
        force "org.apache.logging.log4j:log4j-core:2.20.0"
        force "org.apache.logging.log4j:log4j-jul:2.20.0"
        force "com.fasterxml.jackson:jackson-bom:2.15.1"
        force "com.fasterxml.jackson.core:jackson-databind:2.15.0"
        force "com.fasterxml.jackson.core:jackson-core:2.15.0"
        force "com.fasterxml.jackson.core:jackson-annotations:2.15.1"
        force "com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.15.2"
        force "com.fasterxml.jackson.datatype:jackson-datatype-guava:2.15.2"
        force "com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.15.2"
        force "com.fasterxml.jackson.dataformat:jackson-dataformat-smile:2.15.2"
        force "com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:2.15.2"
        force "io.netty:netty-buffer:4.1.92.Final"
        force "io.netty:netty-codec:4.1.92.Final"
        force "io.netty:netty-codec-http:4.1.92.Final"
        force "io.netty:netty-codec-http2:4.1.92.Final"
        force "io.netty:netty-common:4.1.92.Final"
        force "io.netty:netty-handler:4.1.92.Final"
        force "io.netty:netty-transport-native-unix-common:4.1.92.Final"
        force "io.netty:netty-resolver:4.1.92.Final"
        force "io.netty:netty-transport:4.1.92.Final" 
    }
}

configurations {
    zipArchive
    testImplementation {
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
}

publishing {
    publications {
        pluginZip(MavenPublication) { publication ->
            pom {
                name = 'opensearch-anomaly-detection'
                description = 'OpenSearch anomaly detector plugin'
                licenses {
                    license {
                        name = "The Apache License, Version 2.0"
                        url = "http://www.apache.org/licenses/LICENSE-2.0.txt"
                    }
                }
                developers {
                    developer {
                        name = "OpenSearch"
                        url = "https://github.com/opensearch-project/anomaly-detection"
                    }
                }
            }
        }
    }
}
// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
/*tasks.named('forbiddenApisMain').configure {
    // Only enable limited check because AD code has too many violations.
    replaceSignatureFiles 'jdk-signatures'
    signaturesFiles += files('src/forbidden/ad-signatures.txt')
}*/

//Adds custom file that only has some of the checks for testApis checks since too many violations
//For example, we have to allow @Test to be used in test classes not inherited from LuceneTestCase.
//example: warning for every file: `Forbidden annotation use: org.junit.Test [defaultMessage Just name your test method testFooBar]`
//forbiddenApisTest.setSignaturesFiles(files('src/forbidden/ad-test-signatures.txt'))

// Allow test cases to be named Tests without having to be inherited from LuceneTestCase.
// see https://github.com/elastic/elasticsearch/blob/323f312bbc829a63056a79ebe45adced5099f6e6/buildSrc/src/main/java/org/elasticsearch/gradle/precommit/TestingConventionsTasks.java
testingConventions.enabled = false

licenseHeaders.enabled = false
dependencyLicenses.enabled = false
thirdPartyAudit.enabled = false
loggerUsageCheck.enabled = false
validatePluginZipPom.enabled = false
validateNebulaPom.enabled = false
forbiddenApisMain.enabled = false
forbiddenApisTest.enabled = false
generatePomFileForPluginZipPublication.enabled = false
publishPluginZipPublicationToMavenLocal.enabled = false

// See package README.md for details on using these tasks.
def _numNodes = findProperty('numNodes') as Integer ?: 1

def opensearch_tmp_dir = rootProject.file('build/private/opensearch_tmp').absoluteFile
opensearch_tmp_dir.mkdirs()
boolean isCiServer = System.getenv().containsKey("CI")
test {
    useJUnit()
    options {
    }
    retry {
        if (isCiServer) {
            failOnPassedAfterRetry = false
            maxRetries = 6
            maxFailures = 10
        }
    }
    include '**/*Tests.class'
    systemProperty 'tests.security.manager', 'false'
}

task anomalyDetection(type: JavaExec) {
    group = 'Execution'
    description = 'Run AnomalyDetection Extension.'
    mainClass = 'org.opensearch.ad.AnomalyDetectorExtension'
    classpath = sourceSets.main.runtimeClasspath
}

task integTest(type: RestIntegTestTask) {
    description = "Run tests against a cluster"
    testClassesDirs = sourceSets.test.output.classesDirs
    classpath = sourceSets.test.runtimeClasspath
}

// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
/*
tasks.named("check").configure { dependsOn(integTest) }
*/

task startTestExtension(type: Exec) {
    commandLine 'bash', '-c', "./gradlew anomalyDetection &"
}

integTest {
    retry {
        if (isCiServer) {
            failOnPassedAfterRetry = false
            maxRetries = 6
            maxFailures = 10
        }
    }
    dependsOn "startTestExtension"
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath

    systemProperty "https", System.getProperty("https")
    systemProperty "user", System.getProperty("user")
    systemProperty "password", System.getProperty("password")

    // Only rest case can run with remote cluster
    if (System.getProperty("tests.rest.cluster") != null) {
        filter {
            includeTestsMatching "org.opensearch.ad.rest.*IT"
            includeTestsMatching "org.opensearch.ad.e2e.*IT"
        }
    }

    if (System.getProperty("https") == null || System.getProperty("https") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.rest.SecureADRestIT"
        }
    }

    if (System.getProperty("tests.rest.bwcsuite") == null) {
        filter {
            excludeTestsMatching "org.opensearch.ad.bwc.*IT"
        }
    }

    // The 'doFirst' delays till execution time.
    doFirst {
        // Tell the test JVM if the cluster JVM is running under a debugger so that tests can
        // use longer timeouts for requests.
        def isDebuggingCluster = getDebug() || System.getProperty("test.debug") != null
        systemProperty 'cluster.debug', isDebuggingCluster
        // Set number of nodes system property to be used in tests
        systemProperty 'cluster.number_of_nodes', "${_numNodes}"
        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
        // not being written, the waitForAllConditions ensures it's written
        getClusters().forEach { cluster ->
            cluster.waitForAllConditions()
        }
    }

    // The --debug-jvm command-line option makes the cluster debuggable; this makes the tests debuggable
    if (System.getProperty("test.debug") != null) {
        jvmArgs '-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=*:5005'
    }

    if (printLogs) {
        testLogging {
            showStandardStreams = true
            outputs.upToDateWhen {false}
        }
    }
}

def integADExtensionYml = new org.yaml.snakeyaml.Yaml().load(new File("src/test/resources/org/opensearch/ad/integ/anomaly-detection-extension.yml").newInputStream())

task closeTestExtension (type: Exec) {
    commandLine 'bash', '-c', "kill \$(lsof -i:${integADExtensionYml.port})"
}

tasks.named("integTest").configure { finalizedBy(closeTestExtension) }

testClusters.integTest {
    extension(new ExtensionsProperties("${integADExtensionYml.name}", "${integADExtensionYml.uniqueId}", "${integADExtensionYml.hostAddress}", "${integADExtensionYml.port}", "${integADExtensionYml.version}", "${integADExtensionYml.opensearchVersion}", "${integADExtensionYml.minimumCompatibleVersion}"))
    testDistribution = "ARCHIVE"
    // Cluster shrink exception thrown if we try to set numberOfNodes to 1, so only apply if > 1
    if (_numNodes > 1) numberOfNodes = _numNodes
    // When running integration tests it doesn't forward the --debug-jvm to the cluster anymore
    // i.e. we have to use a custom property to flag when we want to debug elasticsearch JVM
    // since we also support multi node integration tests we increase debugPort per node
    if (System.getProperty("opensearch.debug") != null) {
        def debugPort = 5005
        nodes.forEach { node ->
            node.jvmArgs("-agentlib:jdwp=transport=dt_socket,server=n,suspend=y,address=*:${debugPort}")
            debugPort += 1
        }
    }

    plugin(provider(new Callable<RegularFile>(){
        @Override
        RegularFile call() throws Exception {
            return new RegularFile() {
                @Override
                File getAsFile() {
                    return configurations.zipArchive.asFileTree.getSingleFile()
                }
            }
        }
    }))
}

task integTestRemote(type: RestIntegTestTask) {
    testClassesDirs = sourceSets.test.output.classesDirs
    classpath = sourceSets.test.runtimeClasspath
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath

    systemProperty "https", System.getProperty("https")
    systemProperty "user", System.getProperty("user")
    systemProperty "password", System.getProperty("password")

    // Only rest case can run with remote cluster
    if (System.getProperty("tests.rest.cluster") != null) {
        filter {
            includeTestsMatching "org.opensearch.ad.rest.*IT"
            includeTestsMatching "org.opensearch.ad.e2e.*IT"
        }
    }

    if (System.getProperty("https") == null || System.getProperty("https") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.rest.SecureADRestIT"
        }
    }
}

String bwcVersion = "1.13.0.0"
String baseName = "adBwcCluster"
String bwcFilePath = "src/test/resources/org/opensearch/ad/bwc/"
String bwcJobSchedulerPath = bwcFilePath + "job-scheduler/"
String bwcAnomalyDetectionPath = bwcFilePath + "anomaly-detection/"

2.times {i -> 
    testClusters {
        "${baseName}$i" {
            testDistribution = "ARCHIVE"
            versions = ["7.10.2", opensearch_version]
            numberOfNodes = 3
            plugin(provider(new Callable<RegularFile>(){
                @Override
                RegularFile call() throws Exception {
                    return new RegularFile() {
                        @Override
                        File getAsFile() {
                            if (new File("$project.rootDir/$bwcFilePath/job-scheduler/$bwcVersion").exists()) {
                                project.delete(files("$project.rootDir/$bwcFilePath/job-scheduler/$bwcVersion"))
                            }
                            project.mkdir bwcJobSchedulerPath + bwcVersion
                            ant.get(src: bwcOpenDistroJSDownload,
                                    dest: bwcJobSchedulerPath + bwcVersion,
                                    httpusecaches: false)
                            return fileTree(bwcJobSchedulerPath + bwcVersion).getSingleFile()
                        }
                    }
                }
            }))
            plugin(provider(new Callable<RegularFile>(){
                @Override
                RegularFile call() throws Exception {
                    return new RegularFile() {
                        @Override
                        File getAsFile() {
                            if (new File("$project.rootDir/$bwcFilePath/anomaly-detection/$bwcVersion").exists()) {
                                project.delete(files("$project.rootDir/$bwcFilePath/anomaly-detection/$bwcVersion"))
                            }
                            project.mkdir bwcAnomalyDetectionPath + bwcVersion
                            ant.get(src: bwcOpenDistroADDownload,
                                    dest: bwcAnomalyDetectionPath + bwcVersion,
                                    httpusecaches: false)
                            return fileTree(bwcAnomalyDetectionPath + bwcVersion).getSingleFile()
                        }
                    }
                }
            }))
            setting 'path.repo', "${buildDir}/cluster/shared/repo/${baseName}"
            setting 'http.content_type.required', 'true'
        }
    }
}

List<Provider<RegularFile>> plugins = [
        provider(new Callable<RegularFile>(){
            @Override
            RegularFile call() throws Exception {
                return new RegularFile() {
                    @Override
                    File getAsFile() {
                        return configurations.zipArchive.asFileTree.getSingleFile()
                    }
                }
            }
        }),
        provider(new Callable<RegularFile>(){
            @Override
            RegularFile call() throws Exception {
                return new RegularFile() {
                    @Override
                    File getAsFile() {
                        return fileTree(bwcFilePath + "anomaly-detection/" + project.version).getSingleFile()
                    }
                }
            }
        })
]

// Creates 2 test clusters with 3 nodes of the old version. 
2.times {i -> 
    task "${baseName}#oldVersionClusterTask$i"(type: StandaloneRestIntegTestTask) {
        useCluster testClusters."${baseName}$i"
        filter {
            includeTestsMatching "org.opensearch.ad.bwc.*IT"
        }
        systemProperty 'tests.rest.bwcsuite', 'old_cluster'
        systemProperty 'tests.rest.bwcsuite_round', 'old'
        systemProperty 'tests.plugin_bwc_version', bwcVersion
//        nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}$i".allHttpSocketURI.join(",")}")
//        nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}$i".getName()}")
    }    
}

// Upgrades one node of the old cluster to new OpenSearch version with upgraded plugin version 
// This results in a mixed cluster with 2 nodes on the old version and 1 upgraded node.
// This is also used as a one third upgraded cluster for a rolling upgrade.
task "${baseName}#mixedClusterTask"(type: StandaloneRestIntegTestTask) {
    useCluster testClusters."${baseName}0"
    dependsOn "${baseName}#oldVersionClusterTask0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'first'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
//    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
//    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades the second node to new OpenSearch version with upgraded plugin version after the first node is upgraded.
// This results in a mixed cluster with 1 node on the old version and 2 upgraded nodes.
// This is used for rolling upgrade.
task "${baseName}#twoThirdsUpgradedClusterTask"(type: StandaloneRestIntegTestTask) {
    dependsOn "${baseName}#mixedClusterTask"
    useCluster testClusters."${baseName}0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'second'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
//    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
//    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades the third node to new OpenSearch version with upgraded plugin version after the second node is upgraded.
// This results in a fully upgraded cluster.
// This is used for rolling upgrade.
task "${baseName}#rollingUpgradeClusterTask"(type: StandaloneRestIntegTestTask) {
    dependsOn "${baseName}#twoThirdsUpgradedClusterTask"
    useCluster testClusters."${baseName}0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    mustRunAfter "${baseName}#mixedClusterTask"
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'third'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
//    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
//    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades all the nodes of the old cluster to new OpenSearch version with upgraded plugin version 
// at the same time resulting in a fully upgraded cluster.
task "${baseName}#fullRestartClusterTask"(type: StandaloneRestIntegTestTask) {
    dependsOn "${baseName}#oldVersionClusterTask1"
    useCluster testClusters."${baseName}1"
    doFirst {
      testClusters."${baseName}1".upgradeAllNodesAndPluginsToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'upgraded_cluster'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
//    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}1".allHttpSocketURI.join(",")}")
//    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}1".getName()}")
}

// A bwc test suite which runs all the bwc tasks combined.
task bwcTestSuite(type: StandaloneRestIntegTestTask) {
    exclude '**/*Test*'
    exclude '**/*IT*'
    dependsOn tasks.named("${baseName}#mixedClusterTask")
    dependsOn tasks.named("${baseName}#rollingUpgradeClusterTask")
    dependsOn tasks.named("${baseName}#fullRestartClusterTask")
}

// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
//run {
//    doFirst {
//        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
//        // not being written, the waitForAllConditions ensures it's written
//        getClusters().forEach { cluster ->
//            cluster.waitForAllConditions()
//        }
//    }
//
//// Commented this code until Job Scheduler is published to https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/ with OpenSearch 3.0.0-SNAPSHOT
////    useCluster testClusters.integTest
//}

evaluationDependsOnChildren()

// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
//task release(type: Copy, group: 'build') {
//    dependsOn allprojects*.tasks.build
//    from(zipTree(project.tasks.bundlePlugin.outputs.files.getSingleFile()))
//    into "build/plugins/opensearch-anomaly-detection"
//    includeEmptyDirs = false
//    // ES versions < 6.3 have a top-level opensearch directory inside the plugin zip which we need to remove
//    eachFile { it.path = it.path - "opensearch/" }
//}

List<String> jacocoExclusions = [
        // code for configuration, settings, etc is excluded from coverage
        'org.opensearch.ad.AnomalyDetectorPlugin',

        // rest layer is tested in integration testing mostly, difficult to mock all of it
        'org.opensearch.ad.rest.*',

        'org.opensearch.ad.model.ModelProfileOnNode',
        'org.opensearch.ad.model.InitProgressProfile',
        'org.opensearch.ad.rest.*',
        'org.opensearch.ad.AnomalyDetectorJobRunner',

        // Class containing just constants. Don't need to test
        'org.opensearch.ad.constant.*',

        //'org.opensearch.ad.common.exception.AnomalyDetectionException',
        'org.opensearch.ad.util.ClientUtil',

        'org.opensearch.ad.transport.CronRequest',
        'org.opensearch.ad.AnomalyDetectorRunner',

        // related to transport actions added for security
        'org.opensearch.ad.transport.DeleteAnomalyDetectorTransportAction.1',

        // TODO: unified flow caused coverage drop
        'org.opensearch.ad.transport.DeleteAnomalyResultsTransportAction',
        // TODO: fix unstable code coverage caused by null NodeClient issue
        // https://github.com/opensearch-project/anomaly-detection/issues/241
        'org.opensearch.ad.task.ADBatchTaskRunner',
        'org.opensearch.ad.task.ADTaskManager',
        
        // TODO: Removing dependency on Common Utils "User" class by setting it null
        // means all searches succeed, no failures and reduced coverage on these classes.
        // See https://github.com/opensearch-project/opensearch-sdk/issues/23
        // Reenable these once this plugin has a different security model and failed
        // searches are restored.
        'org.opensearch.ad.auth.UserIdentity',
        'org.opensearch.ad.transport.IndexAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.handler.ADSearchHandler',

        // TODO: Disabled until create components integration is complete
        // https://github.com/opensearch-project/opensearch-sdk-java/issues/283
        'org.opensearch.ad.indices.AnomalyDetectionIndices.IndexState',
        'org.opensearch.ad.feature.SearchFeatureDao.TopEntitiesListener',
        'org.opensearch.ad.ml.CheckpointDao',
        'org.opensearch.ad.transport.handler.MultiEntityResultHandler',
        'org.opensearch.ad.transport.handler.AnomalyResultBulkIndexHandler',

        // TODO: Removing all code except for create detector.
        // See https://github.com/opensearch-project/opensearch-sdk/issues/20
        'org.opensearch.ad.util.ParseUtils',
        'org.opensearch.ad.util.DiscoveryNodeFilterer',
        'org.opensearch.ad.cluster.HashRing',
        'org.opensearch.ad.model.ValidationAspect',
        'org.opensearch.ad.transport.ADCancelTaskNodeRequest',
        'org.opensearch.ad.transport.ADBatchAnomalyResultRequest',
        'org.opensearch.ad.transport.ProfileTransportAction',
        'org.opensearch.ad.transport.SearchTopAnomalyResultAction',
        'org.opensearch.ad.transport.ADBatchAnomalyResultResponse',
        'org.opensearch.ad.transport.SearchAnomalyDetectorAction',
        'org.opensearch.ad.transport.ADCancelTaskRequest',
        'org.opensearch.ad.transport.GetAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.ADBatchTaskRemoteExecutionAction',
        'org.opensearch.ad.transport.ADTaskProfileNodeRequest',
        'org.opensearch.ad.transport.ADBatchTaskRemoteExecutionTransportAction',
        'org.opensearch.ad.transport.ADTaskProfileTransportAction',
        'org.opensearch.ad.transport.StatsAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.StatsAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.DeleteAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.ADCancelTaskAction',
        'org.opensearch.ad.transport.DeleteAnomalyResultsAction',
        'org.opensearch.ad.transport.SearchAnomalyResultAction',
        'org.opensearch.ad.transport.SearchAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.ADCancelTaskTransportAction',
        'org.opensearch.ad.transport.SearchTopAnomalyResultTransportAction',
        'org.opensearch.ad.transport.SearchADTasksTransportAction',
        'org.opensearch.ad.transport.ADBatchAnomalyResultTransportAction',
        'org.opensearch.ad.transport.ADTaskProfileRequest',
        'org.opensearch.ad.transport.SearchADTasksAction',
        'org.opensearch.ad.transport.GetAnomalyDetectorTransportAction.*',
        'org.opensearch.ad.transport.ValidateAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.SearchAnomalyResultTransportAction',
        'org.opensearch.ad.transport.PreviewAnomalyDetectorTransportAction.*',
        'org.opensearch.ad.transport.SearchTopAnomalyResultTransportAction.*',
        'org.opensearch.ad.indices.AnomalyDetectionIndices',
        'org.opensearch.ad.stats.ADStat',
        'org.opensearch.ad.feature.AbstractRetriever',
        'org.opensearch.ad.feature.SearchFeatureDao',
        'org.opensearch.ad.settings.AbstractSetting',
        'org.opensearch.ad.util.ExceptionUtil',
        'org.opensearch.ad.util.DiscoveryNodeFilterer.HotDataNodePredicate',
        'org.opensearch.ad.common.exception.ADVersionException',
        'org.opensearch.ad.common.exception.ResourceNotFoundException',
        'org.opensearch.ad.cluster.ADNodeInfo',
        'org.opensearch.ad.model.ExpectedValueList',
        'org.opensearch.ad.model.DataByFeatureId',
        'org.opensearch.ad.model.AnomalyResult',
        'org.opensearch.ad.model.ADTaskProfile',
        'org.opensearch.ad.model.ADEntityTaskProfile',
        'org.opensearch.ad.model.AnomalyDetectorExecutionInput',
        'org.opensearch.ad.model.DetectionDateRange',
        'org.opensearch.ad.model.DetectorProfile',
        'org.opensearch.ad.transport.DeleteAnomalyDetectorRequest',
        'org.opensearch.ad.transport.ADTaskProfileAction',
        'org.opensearch.ad.transport.ProfileAction',
        'org.opensearch.ad.transport.GetAnomalyDetectorResponse',
        'org.opensearch.ad.transport.EntityResultRequest',
        'org.opensearch.ad.transport.AnomalyDetectorJobRequest',
        'org.opensearch.ad.transport.ADBatchAnomalyResultAction',
        'org.opensearch.ad.transport.ADTaskProfileNodeResponse',
        'org.opensearch.ad.transport.AnomalyDetectorJobAction',
        'org.opensearch.ad.transport.AnomalyResultTransportAction',
        'org.opensearch.ad.transport.GetAnomalyDetectorAction',
        'org.opensearch.ad.transport.AnomalyDetectorJobTransportAction',
        'org.opensearch.ad.transport.AnomalyDetectorJobResponse',
        'org.opensearch.ad.transport.GetAnomalyDetectorRequest',
        'org.opensearch.ad.transport.AnomalyResultTransportAction',
        'org.opensearch.ad.transport.DeleteAnomalyDetectorAction',
        'org.opensearch.ad.transport.AnomalyResultTransportAction.EntityResultListener',
        'org.opensearch.ad.feature.CompositeRetriever',
        'org.opensearch.ad.ml.EntityColdStarter',
        'org.opensearch.ad.AbstractProfileRunner',
        'org.opensearch.ad.Name',
        'org.opensearch.ad.model.EntityProfile.Builder',
        'org.opensearch.ad.transport.AnomalyResultTransportAction.PageListener',
        'org.opensearch.ad.feature.CompositeRetriever.Page',
        'org.opensearch.ad.feature.CompositeRetriever.PageIterator',
        'org.opensearch.ad.feature.CompositeRetriever.PageIterator.*',
        'org.opensearch.ad.AnomalyDetectorExtension',
        'org.opensearch.ad.transport.ADJobRunnerTransportAction*',
        'org.opensearch.ad.AnomalyDetectorProfileRunner',
        'org.opensearch.ad.EntityProfileRunner',
        'org.opensearch.ad.common.exception.InternalFailure',
        'org.opensearch.ad.cluster.HourlyCron',
        'org.opensearch.ad.cluster.ADClusterEventListener',
        'org.opensearch.ad.cluster.DailyCron',
        'org.opensearch.ad.cluster.diskcleanup.IndexCleanup',
        'org.opensearch.ad.cluster.diskcleanup.ModelCheckpointIndexRetention',
        'org.opensearch.ad.transport.handler.AnomalyIndexHandler',
        'org.opensearch.ad.transport.AnomalyResultTransportAction.RCFActionListener',
        'org.opensearch.ad.transport.AnomalyResultRequest',
        'org.opensearch.ad.transport.AnomalyResultAction',
        'org.opensearch.ad.transport.AnomalyResultResponse',
        'org.opensearch.ad.common.exception.ClientException',
        'org.opensearch.ad.caching.DoorKeeper',
        'org.opensearch.ad.caching.CacheProvider',
        'org.opensearch.ad.util.IndexUtils',
        'org.opensearch.ad.cluster.ClusterManagerEventListener',
        'org.opensearch.ad.cluster.ClusterManagerEventListener.*',
        'org.opensearch.ad.transport.ADStatsNodesAction',
        'org.opensearch.ad.transport.BackPressureRouting',
        'org.opensearch.ad.transport.ADStatsNodesTransportAction',
        'org.opensearch.ad.stats.InternalStatNames',
        'org.opensearch.ad.NodeState',
        'org.opensearch.ad.transport.DeleteModelRequest',
        'org.opensearch.ad.transport.StopDetectorTransportAction',
        'org.opensearch.ad.transport.StopDetectorRequest',
        'org.opensearch.ad.ratelimit.RateLimitedRequestWorker',
        'org.opensearch.ad.ratelimit.QueuedRequest',
        'org.opensearch.ad.ratelimit.CheckpointReadWorker',
        'org.opensearch.ad.ratelimit.ConcurrentWorker',
        'org.opensearch.ad.ratelimit.RateLimitedRequestWorker.RequestQueue',
        'org.opensearch.ad.MaintenanceState',
        'org.opensearch.ad.AnomalyDetectorExtension.*',
        'org.opensearch.ad.EntityProfileRunner',
        'org.opensearch.ad.transport.ADResultBulkTransportAction',
        'org.opensearch.ad.transport.ADResultBulkRequest',
        'org.opensearch.ad.transport.ADResultBulkAction',
        'org.opensearch.ad.ratelimit.ResultWriteRequest',
        'org.opensearch.ad.AnomalyDetectorJobRunner.*',
        'org.opensearch.ad.transport.SearchAnomalyDetectorInfoTransportAction.*',
        'org.opensearch.ad.transport.RCFPollingAction',
        'org.opensearch.ad.transport.RCFPollingRequest',
        'org.opensearch.ad.transport.RCFPollingTransportAction',
        'org.opensearch.ad.transport.RCFPollingTransportAction.*',
        'org.opensearch.ad.transport.RCFPollingResponse',

]

// Changed the jacoco threshold as extension doesn't support threadpool and multi node support as of now. Code coverage would fail.
jacocoTestCoverageVerification {
    violationRules {
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'BRANCH'
                minimum = 0.40
            }
        }
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'LINE'
                value = 'COVEREDRATIO'
                minimum = 0.50
            }
        }
    }
}

jacocoTestReport {
    reports {
        xml.required = true
        html.required = true
    }
}

check.dependsOn jacocoTestCoverageVerification
jacocoTestCoverageVerification.dependsOn jacocoTestReport

dependencies {
    zipArchive group: 'org.opensearch.plugin', name:'opensearch-job-scheduler', version: "${opensearch_build}"
    compileOnly "org.opensearch:opensearch:${opensearch_version}"
    compileOnly "org.opensearch.plugin:opensearch-scripting-painless-spi:${opensearch_version}"
    implementation "org.opensearch:opensearch-job-scheduler-spi:${job_scheduler_version}"
//  Removed Common Utils dependency from AD
//    implementation "org.opensearch:common-utils:${common_utils_version}"
    implementation "org.opensearch:opensearch-job-scheduler:${job_scheduler_version}"
    implementation "org.opensearch.sdk:opensearch-sdk-java:2.0.0-SNAPSHOT"
    implementation "com.google.inject:guice:7.0.0"
    implementation "org.opensearch.client:opensearch-java:${opensearch_version}"
    implementation "org.opensearch.client:opensearch-rest-client:${opensearch_version}"
    implementation "org.opensearch.client:opensearch-rest-high-level-client:${opensearch_version}"
    implementation group: 'com.google.guava', name: 'guava', version:'31.1-jre'
    implementation group: 'com.google.guava', name: 'failureaccess', version:'1.0.1'
    implementation group: 'org.javassist', name: 'javassist', version:'3.28.0-GA'
    implementation group: 'org.apache.commons', name: 'commons-math3', version: '3.6.1'
    implementation group: 'com.google.code.gson', name: 'gson', version: '2.8.9'
    implementation group: 'com.yahoo.datasketches', name: 'sketches-core', version: '0.13.4'
    implementation group: 'com.yahoo.datasketches', name: 'memory', version: '0.12.2'
    implementation group: 'commons-lang', name: 'commons-lang', version: '2.6'
    implementation group: 'org.apache.commons', name: 'commons-pool2', version: '2.10.0'
    implementation 'software.amazon.randomcutforest:randomcutforest-serialization:3.0-rc3'
    implementation 'software.amazon.randomcutforest:randomcutforest-parkservices:3.0-rc3'
    implementation 'software.amazon.randomcutforest:randomcutforest-core:3.0-rc3'

    // force Jackson version to avoid version conflict issue
//    implementation "com.fasterxml.jackson.core:jackson-core:${versions.jackson}"
//    implementation "com.fasterxml.jackson.core:jackson-databind:${versions.jackson}"
//    implementation "com.fasterxml.jackson.core:jackson-annotations:${versions.jackson}"

    // used for serializing/deserializing rcf models.
    implementation group: 'io.protostuff', name: 'protostuff-core', version: '1.8.0'
    implementation group: 'io.protostuff', name: 'protostuff-runtime', version: '1.8.0'
    implementation group: 'io.protostuff', name: 'protostuff-api', version: '1.8.0'
    implementation group: 'io.protostuff', name: 'protostuff-collectionschema', version: '1.8.0'
    implementation group: 'org.apache.commons', name: 'commons-lang3', version: '3.12.0'

    implementation "org.jacoco:org.jacoco.agent:0.8.5"
    implementation ("org.jacoco:org.jacoco.ant:0.8.5") {
        exclude group: 'org.ow2.asm', module: 'asm-commons'
        exclude group: 'org.ow2.asm', module: 'asm'
        exclude group: 'org.ow2.asm', module: 'asm-tree'
    }

    testImplementation group: 'org.opensearch.test', name: 'framework', version:"${opensearch_version}"
    testImplementation group: 'pl.pragmatists', name: 'JUnitParams', version: '1.1.1'
    testImplementation group: 'org.mockito', name: 'mockito-core', version: '2.25.0'
    testImplementation group: 'org.powermock', name: 'powermock-api-mockito2', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-module-junit4', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-module-junit4-common', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-core', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-api-support', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-reflect', version: '2.0.7'
    testImplementation group: 'org.objenesis', name: 'objenesis', version: '3.0.1'
    testImplementation group: 'net.bytebuddy', name: 'byte-buddy', version: '1.9.15'
    testImplementation group: 'net.bytebuddy', name: 'byte-buddy-agent', version: '1.9.15'
    testCompileOnly 'org.apiguardian:apiguardian-api:1.1.0'
    testCompileOnly 'junit:junit:4.13.2'
}

compileJava.options.compilerArgs << "-Xlint:-deprecation,-rawtypes,-serial,-try,-unchecked"

apply plugin: 'com.netflix.nebula.ospackage'

// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
// This is afterEvaluate because the bundlePlugin ZIP task is updated afterEvaluate and changes the ZIP name to match the plugin name
/*afterEvaluate {
    ospackage {
        packageName = "${name}"
        release = isSnapshot ? "0.1" : '1'
        version = "${project.version}" - "-SNAPSHOT"

        into '/usr/share/opensearch/plugins'
        from(zipTree(bundlePlugin.archivePath)) {
            into opensearchplugin.name
        }

        user 'root'
        permissionGroup 'root'
        fileMode 0644
        dirMode 0755

        requires('opensearch', '3.0.0', EQUAL)
        packager = 'Amazon'
        vendor = 'Amazon'
        os = 'LINUX'
        prefix '/usr'

        license 'ASL-2.0'
        maintainer 'OpenSearch <opensearch@amazon.com>'
        url 'https://opensearch.org/downloads.html'
        summary '''
         Anomaly Detection plugin for OpenSearch.
         Reference documentation can be found at https://opensearch.org/docs/monitoring-plugins/ad/index/.
    '''.stripIndent().replace('\n', ' ').trim()
    }


    buildDeb {
        arch = 'all'
        dependsOn 'assemble'
        finalizedBy 'renameDeb'
        task renameDeb(type: Copy) {
            from("$buildDir/distributions")
            into("$buildDir/distributions")
            include archiveName
            rename archiveName, "${packageName}-${version}.deb"
            doLast { delete file("$buildDir/distributions/$archiveName") }
        }
    }

    task buildPackages(type: GradleBuild) {
        tasks = ['build', 'buildDeb']
    }
}*/

spotless {
    java {
        removeUnusedImports()
        importOrder 'java', 'javax', 'org', 'com'
        if (System.getProperty('spotless.paddedcell') != null) {
            paddedCell()
        }
        eclipse().configFile rootProject.file('.eclipseformat.xml')
    }
}

// no need to validate pom, as we do not upload to maven/sonatype
// Commented this code until https://github.com/opensearch-project/opensearch-sdk-java/issues/144
/*validateNebulaPom.enabled = false

tasks.withType(licenseHeaders.class) {
    additionalLicense 'AL   ', 'Apache', 'Licensed under the Apache License, Version 2.0 (the "License")'
}*/

// show test results so that we can record information like precion/recall results of correctness testing.
if (printLogs) {
    test {
        testLogging {
            showStandardStreams = true
            outputs.upToDateWhen {false}
        }
    }
}
