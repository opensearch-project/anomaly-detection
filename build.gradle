/*
 * SPDX-License-Identifier: Apache-2.0
 *
 * The OpenSearch Contributors require contributions made to
 * this file be licensed under the Apache-2.0 license or a
 * compatible open source license.
 *
 * Modifications Copyright OpenSearch Contributors. See
 * GitHub history for details.
 */


import org.opensearch.gradle.testclusters.OpenSearchCluster

import javax.net.ssl.HostnameVerifier
import javax.net.ssl.HttpsURLConnection
import javax.net.ssl.SSLContext
import javax.net.ssl.SSLSession
import javax.net.ssl.TrustManager
import javax.net.ssl.X509TrustManager
import java.nio.charset.StandardCharsets
import java.nio.file.Files
import java.security.GeneralSecurityException
import java.security.cert.X509Certificate
import java.util.concurrent.Callable
import org.opensearch.gradle.test.RestIntegTestTask
import org.opensearch.gradle.testclusters.StandaloneRestIntegTestTask
import org.opensearch.gradle.info.BuildParams
import java.util.stream.Collectors


import java.util.concurrent.TimeUnit
import java.util.function.Predicate
import java.util.stream.Collectors

buildscript {
    ext {
        opensearch_group = "org.opensearch"
        isSnapshot = "true" == System.getProperty("build.snapshot", "true")
        opensearch_version = System.getProperty("opensearch.version", "3.4.0-SNAPSHOT")
        buildVersionQualifier = System.getProperty("build.version_qualifier", "")
        // 3.0.0-SNAPSHOT -> 3.0.0.0-SNAPSHOT
        version_tokens = opensearch_version.tokenize('-')
        opensearch_build = version_tokens[0] + '.0'
        plugin_no_snapshot = opensearch_build
        if (buildVersionQualifier) {
            opensearch_build += "-${buildVersionQualifier}"
            plugin_no_snapshot += "-${buildVersionQualifier}"
        }
        if (isSnapshot) {
            opensearch_build += "-SNAPSHOT"
        }
        opensearch_no_snapshot = opensearch_version.replace("-SNAPSHOT","")
        js_resource_folder = "src/test/resources/job-scheduler"
        common_utils_version = System.getProperty("common_utils.version", opensearch_build)
        job_scheduler_version = System.getProperty("job_scheduler.version", opensearch_build)
        bwcVersionShort = "2.19.1"
        bwcVersion = bwcVersionShort + ".0"
        bwcOpenSearchADDownload = 'https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/' + bwcVersionShort + '/latest/linux/x64/tar/builds/' +
                'opensearch/plugins/opensearch-anomaly-detection-' + bwcVersion + '.zip'
        bwcOpenSearchJSDownload = 'https://ci.opensearch.org/ci/dbc/distribution-build-opensearch/' + bwcVersionShort + '/latest/linux/x64/tar/builds/' +
                'opensearch/plugins/opensearch-job-scheduler-' + bwcVersion + '.zip'
        baseName = "adBwcCluster"
        bwcFilePath = "src/test/resources/org/opensearch/ad/bwc/"
        bwcJobSchedulerPath = bwcFilePath + "job-scheduler/"
        bwcAnomalyDetectionPath = bwcFilePath + "anomaly-detection/"
        jacksonVersion = "2.18.2"
        // gradle build won't print logs during test by default unless there is a failure.
        // It is useful to record intermediately information like prediction precision and recall.
        // This option turn on log printing during tests.
        printLogs = "true" == System.getProperty("test.logs", "false")
    }

    repositories {
        mavenLocal()
        maven { url = "https://ci.opensearch.org/ci/dbc/snapshots/maven/" }
        mavenCentral()
        maven { url = "https://plugins.gradle.org/m2/" }
    }

    dependencies {
        classpath "${opensearch_group}.gradle:build-tools:${opensearch_version}"
    }
}

plugins {
    id 'com.netflix.nebula.ospackage' version "12.1.0"
    id "com.diffplug.spotless" version "6.25.0"
    id 'java-library'
    id 'org.gradle.test-retry' version '1.6.0'
    id "de.undercouch.download" version "5.6.0"
}

tasks.withType(JavaCompile) {
    options.encoding = "UTF-8"
}
tasks.withType(Test) {
    systemProperty "file.encoding", "UTF-8"
    jvmArgs("--add-opens", "java.base/java.time=ALL-UNNAMED")
    jvmArgs("--add-opens", "java.base/java.util.stream=ALL-UNNAMED")

    // PowerMock related tests like SearchFeatureDaoTests relies on modifying the bytecode of
    // classes during runtime, which can conflict with the module system introduced in Java 9.
    // To resolve this issue, we use the --add-opens option to explicitly open the java.util
    // and java.lang package to PowerMock. This option allows PowerMock to access non-public
    // members of the java.util and java.lang package.
    jvmArgs('--add-opens', 'java.base/java.util=ALL-UNNAMED')
    jvmArgs('--add-opens', 'java.base/java.lang=ALL-UNNAMED')
}
tasks.withType(Javadoc) {
    options.encoding = 'UTF-8'
}
tasks.withType(AbstractArchiveTask) {
    preserveFileTimestamps = false
    reproducibleFileOrder = true
}

repositories {
    mavenLocal()
    maven { url = "https://ci.opensearch.org/ci/dbc/snapshots/maven/" }
    mavenCentral()
    maven { url = "https://plugins.gradle.org/m2/" }
    maven { url = "https://ci.opensearch.org/ci/dbc/snapshots/lucene/" }
}
configurations {
    zipArchive
    //hamcrest-core needs to be ignored since it causes jar hell exception due to a conflict during testing
    testImplementation {
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
    opensearchPlugin
}

dependencies {
    compileOnly "org.opensearch:opensearch-security-spi:${opensearch_build}"
    implementation "org.opensearch:opensearch:${opensearch_version}"
    compileOnly "org.opensearch.plugin:opensearch-scripting-painless-spi:${opensearch_version}"
    compileOnly "org.opensearch:opensearch-job-scheduler-spi:${job_scheduler_version}"
    implementation "org.opensearch:common-utils:${common_utils_version}"
    implementation "org.opensearch.client:opensearch-rest-client:${opensearch_version}"
    implementation 'com.google.guava:guava:33.4.5-jre'
    implementation 'com.google.guava:failureaccess:1.0.3'
    implementation 'org.apache.commons:commons-math3:3.6.1'
    implementation 'com.google.code.gson:gson:2.11.0'
    implementation 'com.yahoo.datasketches:sketches-core:0.13.4'
    implementation 'com.yahoo.datasketches:memory:0.12.2'
    implementation 'org.apache.commons:commons-pool2:2.12.0'
    implementation 'software.amazon.randomcutforest:randomcutforest-serialization:4.4.0'
    implementation 'software.amazon.randomcutforest:randomcutforest-parkservices:4.4.0'
    implementation 'software.amazon.randomcutforest:randomcutforest-core:4.4.0'


    // we inherit jackson-core from opensearch core
    implementation("com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}")
    implementation("com.fasterxml.jackson.core:jackson-annotations:${jacksonVersion}")

    // used for serializing/deserializing rcf models.
    implementation 'io.protostuff:protostuff-core:1.8.0'
    implementation 'io.protostuff:protostuff-runtime:1.8.0'
    implementation 'io.protostuff:protostuff-api:1.8.0'
    implementation 'io.protostuff:protostuff-collectionschema:1.8.0'
    implementation 'org.apache.commons:commons-lang3:3.18.0'


    implementation "org.jacoco:org.jacoco.agent:0.8.13"
    implementation ("org.jacoco:org.jacoco.ant:0.8.13") {
        exclude group: 'org.ow2.asm', module: 'asm-commons'
        exclude group: 'org.ow2.asm', module: 'asm'
        exclude group: 'org.ow2.asm', module: 'asm-tree'
    }

    // used for output encoding of config descriptions
    implementation 'org.owasp.encoder:encoder:1.3.1'

    testImplementation 'org.awaitility:awaitility:4.3.0'
    testImplementation 'pl.pragmatists:JUnitParams:1.1.1'
    testImplementation 'org.mockito:mockito-core:5.20.0'
    testImplementation 'org.objenesis:objenesis:3.4'
    testImplementation 'net.bytebuddy:byte-buddy:1.17.7'
    testImplementation 'net.bytebuddy:byte-buddy-agent:1.17.7'
    testCompileOnly 'org.apiguardian:apiguardian-api:1.1.2'
    // jupiter is required to run unit tests not inherited from OpenSearchTestCase (e.g., PreviousValueImputerTests)
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.14.1'
    testImplementation  'org.junit.jupiter:junit-jupiter-params:5.14.1'
    testImplementation 'org.junit.jupiter:junit-jupiter-engine:5.14.1'
    testImplementation "org.opensearch:opensearch-core:${opensearch_version}"
    testRuntimeOnly("org.junit.platform:junit-platform-launcher:1.11.2")
    testCompileOnly 'junit:junit:4.13.2'

    opensearchPlugin "org.opensearch.plugin:opensearch-job-scheduler:${opensearch_build}@zip"
    opensearchPlugin "org.opensearch.plugin:opensearch-security:${opensearch_build}@zip"
    testImplementation 'org.reflections:reflections:0.10.2'

    testImplementation "org.opensearch.test:framework:${opensearch_version}"
}

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'opensearch.opensearchplugin'
apply plugin: 'opensearch.testclusters'
apply plugin: 'base'
apply plugin: 'jacoco'
apply plugin: 'eclipse'
apply plugin: 'opensearch.pluginzip'
apply plugin: 'opensearch.java-agent'

ext {
    isSnapshot = "true" == System.getProperty("build.snapshot", "true")
    buildVersionQualifier = System.getProperty("build.version_qualifier")
}

allprojects {
    group = 'org.opensearch'

    version = "${opensearch_build}"

    plugins.withId('jacoco') {
        jacoco.toolVersion = '0.8.13'
    }
}

java {
  targetCompatibility = JavaVersion.VERSION_21
  sourceCompatibility = JavaVersion.VERSION_21
}

ext {
    projectSubstitutions = [:]
    licenseFile = rootProject.file('LICENSE.txt')
    noticeFile = rootProject.file('NOTICE.txt')

    runIntegTestWithSecurityPlugin= System.getProperty("security")
    if (runIntegTestWithSecurityPlugin == "true") {
        ['esnode.pem', 'esnode-key.pem', 'kirk.pem', 'kirk-key.pem', 'root-ca.pem', 'sample.pem', 'test-kirk.jks'].forEach { file ->
            File local = getLayout().getBuildDirectory().file(file).get().getAsFile()
            download.run {
                src "https://raw.githubusercontent.com/opensearch-project/security/refs/heads/main/bwc-test/src/test/resources/security/" + file
                dest local
                overwrite false
            }
            processTestResources {
                from(local)
            }
        }
    }
}

opensearchplugin {
    name = 'opensearch-anomaly-detection'
    description = 'OpenSearch anomaly detector plugin'
    classname = 'org.opensearch.timeseries.TimeSeriesAnalyticsPlugin'
    extendedPlugins = ['lang-painless', 'opensearch-job-scheduler', 'opensearch-security;optional=true']
}

// Handle case where older versions of esplugin doesn't expose the joda time version it uses
configurations.all {
    if (it.state != Configuration.State.UNRESOLVED) return
    resolutionStrategy {
        force "joda-time:joda-time:${versions.joda}"
        force "commons-logging:commons-logging:${versions.commonslogging}"
        force "org.apache.httpcomponents.core5:httpcore5:${versions.httpcore5}"
        force "org.apache.httpcomponents.client5:httpclient5:${versions.httpclient5}"

        force "org.mockito:mockito-core:5.20.0"
        force "org.objenesis:objenesis:3.4"
        force "net.bytebuddy:byte-buddy:1.17.7"
        force "net.bytebuddy:byte-buddy-agent:1.17.7"
        force "com.google.code.gson:gson:2.11.0"
        force "junit:junit:4.13.2"

        force "com.google.guava:guava:33.4.5-jre" // CVE for 31.1
        force("com.fasterxml.jackson.core:jackson-core:${jacksonVersion}")
        force "org.eclipse.platform:org.eclipse.core.runtime:3.29.0" // CVE for < 3.29.0
        force "org.ow2.asm:asm:9.7.1"
    }
}


publishing {
    publications {
        pluginZip(MavenPublication) { publication ->
            pom {
                name = opensearchplugin.name
                description = opensearchplugin.description
                groupId = "org.opensearch.plugin"
                licenses {
                    license {
                        name = "The Apache License, Version 2.0"
                        url = "http://www.apache.org/licenses/LICENSE-2.0.txt"
                    }
                }
                developers {
                    developer {
                        name = "OpenSearch"
                        url = "https://github.com/opensearch-project/anomaly-detection"
                    }
                }
            }
        }
    }

    repositories {
        maven {
            name = "Snapshots"
            url = System.getenv("MAVEN_SNAPSHOTS_S3_REPO")
            credentials(AwsCredentials) {
                accessKey = System.getenv("AWS_ACCESS_KEY_ID")
                secretKey = System.getenv("AWS_SECRET_ACCESS_KEY")
                sessionToken = System.getenv("AWS_SESSION_TOKEN")
            }
        }
    }
}

tasks.named('forbiddenApisMain').configure {
    // Only enable limited check because AD code has too many violations.
    replaceSignatureFiles 'jdk-signatures'
    signaturesFiles += files('src/forbidden/ad-signatures.txt')
}

//Adds custom file that only has some of the checks for testApis checks since too many violations
//For example, we have to allow @Test to be used in test classes not inherited from LuceneTestCase.
//example: warning for every file: `Forbidden annotation use: org.junit.Test [defaultMessage Just name your test method testFooBar]`
forbiddenApisTest.setSignaturesFiles(files('src/forbidden/ad-test-signatures.txt'))

// Allow test cases to be named Tests without having to be inherited from LuceneTestCase.
// see https://github.com/elastic/elasticsearch/blob/323f312bbc829a63056a79ebe45adced5099f6e6/buildSrc/src/main/java/org/elasticsearch/gradle/precommit/TestingConventionsTasks.java
testingConventions.enabled = false

licenseHeaders.enabled = true
dependencyLicenses.enabled = false
thirdPartyAudit.enabled = false
loggerUsageCheck.enabled = false

// See package README.md for details on using these tasks.
def _numNodes = findProperty('numNodes') as Integer ?: 1

def opensearch_tmp_dir = rootProject.file('build/private/opensearch_tmp').absoluteFile
opensearch_tmp_dir.mkdirs()
test {
    retry {
        if (BuildParams.isCi()) {
            maxRetries = 6
            maxFailures = 10
        }
        failOnPassedAfterRetry = false
    }
    include '**/*Tests.class'
    systemProperty 'tests.security.manager', 'false'

    if (System.getProperty("model-benchmark") == null || System.getProperty("model-benchmark") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.ml.HCADModelPerfTests"
        }
    }
}

task integTest(type: RestIntegTestTask) {
    description = "Run tests against a cluster"
    testClassesDirs = sourceSets.test.output.classesDirs
    classpath = sourceSets.test.runtimeClasspath
}
tasks.named("check").configure { dependsOn(integTest) }

integTest {
    retry {
        if (BuildParams.isCi()) {
            maxRetries = 6
            maxFailures = 10
        }
        failOnPassedAfterRetry = false
    }
    dependsOn "bundlePlugin"
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath

    systemProperty "https", System.getProperty("https")
    systemProperty "user", System.getProperty("user")
    systemProperty "password", System.getProperty("password")
    systemProperty "resource_sharing.enabled", System.getProperty("resource_sharing.enabled")

    // Only rest case can run with remote cluster
    if (System.getProperty("tests.rest.cluster") != null) {
        filter {
            includeTestsMatching "org.opensearch.ad.rest.*IT"
            includeTestsMatching "org.opensearch.ad.e2e.*IT"
            includeTestsMatching "org.opensearch.forecast.rest.*IT"
            includeTestsMatching "org.opensearch.forecast.e2e.*IT"
        }
    }

    if (System.getProperty("https") == null || System.getProperty("https") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.rest.SecureADRestIT"
            excludeTestsMatching "org.opensearch.forecast.rest.SecureForecastRestIT"
        }
    }

    if (System.getProperty("tests.rest.bwcsuite") == null) {
        filter {
            excludeTestsMatching "org.opensearch.ad.bwc.*IT"
        }
    }

    if (System.getProperty("model-benchmark") == null || System.getProperty("model-benchmark") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.*ModelPerfIT"
        }
    }

    if (System.getProperty("long-running") == null || System.getProperty("long-running") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.SingleStreamSmokeIT"
            excludeTestsMatching "org.opensearch.ad.e2e.RealTimeFrequencySmokeIT"
            excludeTestsMatching "org.opensearch.forecast.rest.LongRunningForecastRestApiIT"
        }
    }

    if (System.getProperty("perf") == null || System.getProperty("perf") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.BatchADSchedulingCheckpointIT"
        }
    }

    // The 'doFirst' delays till execution time.
    doFirst {
        // Tell the test JVM if the cluster JVM is running under a debugger so that tests can
        // use longer timeouts for requests.
        def isDebuggingCluster = getDebug() || System.getProperty("test.debug") != null
        systemProperty 'cluster.debug', isDebuggingCluster
        // Set number of nodes system property to be used in tests
        systemProperty 'cluster.number_of_nodes', "${_numNodes}"
        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
        // not being written, the waitForAllConditions ensures it's written
        getClusters().forEach { cluster ->
            cluster.waitForAllConditions()
        }
        println 'Running in CI mode:' + BuildParams.isCi()
    }

    // The --debug-jvm command-line option makes the cluster debuggable; this makes the tests debuggable
    if (System.getProperty("test.debug") != null) {
        jvmArgs '-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=*:5005'
    }

    if (printLogs) {
        testLogging {
            showStandardStreams = true
            outputs.upToDateWhen {false}
        }
    }
}

ext.resolvePluginFile = { pluginId ->
    return new Callable<RegularFile>() {
        @Override
        RegularFile call() throws Exception {
            return new RegularFile() {
                @Override
                File getAsFile() {
                    return configurations.opensearchPlugin.resolvedConfiguration.resolvedArtifacts
                            .find { ResolvedArtifact f ->
                                f.name.startsWith(pluginId)
                            }
                            .file
                }
            }
        }
    }
}
def jobSchedulerFile = resolvePluginFile("opensearch-job-scheduler")
def securityPluginFile = resolvePluginFile("opensearch-security")

// === Setup security test ===
// This flag indicates the existence of security plugin
def securityEnabled = System.getProperty("security", "false") == "true" || System.getProperty("https", "false") == "true"

testClusters.integTest {
    testDistribution = "ARCHIVE"
    // Cluster shrink exception thrown if we try to set numberOfNodes to 1, so only apply if > 1
    if (_numNodes > 1) numberOfNodes = _numNodes
    configureClusterPlugins(delegate, jobSchedulerFile, securityPluginFile, securityEnabled)
    nodes.each { it.jvmArgs("-Xms1g", "-Xmx1g") }
}

testClusters {
    leaderCluster {
        testDistribution = "ARCHIVE"
        setting 'path.repo', file("${buildDir}/leaderCluster/repo").absolutePath
        setting 'discovery.type', 'single-node'
        // Add custom attribute to identify this cluster
        setting 'node.attr.cluster_role', 'leader'
        configureClusterPlugins(delegate, jobSchedulerFile, securityPluginFile, securityEnabled)
    }

    followCluster {
        testDistribution = "ARCHIVE"
        setting 'path.repo', file("${buildDir}/followCluster/repo").absolutePath
        setting 'discovery.type', 'single-node'
        // Add custom attribute to identify this cluster
        setting 'node.attr.cluster_role', 'follower'
        configureClusterPlugins(delegate, jobSchedulerFile, securityPluginFile, securityEnabled)
    }
}

def configureClusterPlugins(cluster, jobSchedulerFile, securityPluginFile, securityEnabled) {
    // When running integration tests it doesn't forward the --debug-jvm to the cluster anymore
    // i.e. we have to use a custom property to flag when we want to debug elasticsearch JVM
    // since we also support multi node integration tests we increase debugPort per node
    if (System.getProperty("opensearch.debug") != null) {
        def debugPort = 5005
        cluster.nodes.forEach { node ->
            // server=n,suspend=y -> node tries to connect to a debugger and hence test runs fails with
            //            Exec output and error:
            //            | Output for ./bin/opensearch-plugin:ERROR: transport error 202: connect failed: Connection refused
            //            | ERROR: JDWP Transport dt_socket failed to initialize, TRANSPORT_INIT(510)
            //                    | JDWP exit error AGENT_ERROR_TRANSPORT_INIT(197): No transports initialized [src/jdk.jdwp.agent/share/native/libjdwp/debugInit.c:700].
            // So instead, we listen to a debugger by saying server=y and suspend=n
            node.jvmArgs("-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:${debugPort}")
            debugPort += 1
        }
    }
    cluster.with {
        plugin(project.tasks.bundlePlugin.archiveFile)
        plugin(provider(jobSchedulerFile))
        if (securityEnabled) {
            plugin(provider(securityPluginFile))
        }

        // As of ES 7.7.0 the opendistro-anomaly-detection plugin is being added to the list of plugins for the testCluster during build before
        // the opensearch-job-scheduler plugin, which is causing build failures. From the stack trace, this looks like a bug.
        //
        // Exception in thread "main" java.lang.IllegalArgumentException: Missing plugin [opensearch-job-scheduler], dependency of [opendistro-anomaly-detection]
        //       at org.opensearch.plugins.PluginsService.addSortedBundle(PluginsService.java:452)
        //
        // One explanation is that ES build script sort plugins according to the natural ordering of their names.
        // opendistro-anomaly-detection comes before opensearch-job-scheduler.
        //
        // The following is a comparison of different plugin installation order:
        // Before 7.7:
        // ./bin/elasticsearch-plugin install --batch file:opendistro-anomaly-detection.zip file:opensearch-job-scheduler.zip
        //
        // After 7.7:
        // ./bin/elasticsearch-plugin install --batch file:opensearch-job-scheduler.zip file:opendistro-anomaly-detection.zip
        //
        // A temporary hack is to reorder the plugins list after evaluation but prior to task execution when the plugins are installed.
        cluster.nodes.each { node ->
            def plugins = node.plugins
            def firstPlugin = plugins.get(0)
            plugins.remove(0)
            plugins.add(firstPlugin)

            if (securityEnabled) {
                node.extraConfigFile("kirk.pem", file("build/resources/test/kirk.pem"))
                node.extraConfigFile("kirk-key.pem", file("build/resources/test/kirk-key.pem"))
                node.extraConfigFile("esnode.pem", file("build/resources/test/esnode.pem"))
                node.extraConfigFile("esnode-key.pem", file("build/resources/test/esnode-key.pem"))
                node.extraConfigFile("root-ca.pem", file("build/resources/test/root-ca.pem"))
                node.setting("plugins.security.ssl.transport.pemcert_filepath", "esnode.pem")
                node.setting("plugins.security.ssl.transport.pemkey_filepath", "esnode-key.pem")
                node.setting("plugins.security.ssl.transport.pemtrustedcas_filepath", "root-ca.pem")
                node.setting("plugins.security.ssl.transport.enforce_hostname_verification", "false")
                node.setting("plugins.security.ssl.http.enabled", "true")
                node.setting("plugins.security.ssl.http.pemcert_filepath", "esnode.pem")
                node.setting("plugins.security.ssl.http.pemkey_filepath", "esnode-key.pem")
                node.setting("plugins.security.ssl.http.pemtrustedcas_filepath", "root-ca.pem")
                node.setting("plugins.security.allow_unsafe_democertificates", "true")
                node.setting("plugins.security.allow_default_init_securityindex", "true")
                node.setting("plugins.security.authcz.admin_dn", "\n - CN=kirk,OU=client,O=client,L=test,C=de")
                node.setting("plugins.security.audit.type", "internal_opensearch")
                node.setting("plugins.security.enable_snapshot_restore_privilege", "true")
                node.setting("plugins.security.check_snapshot_restore_write_privileges", "true")
                node.setting("plugins.security.restapi.roles_enabled", "[\"all_access\", \"security_rest_api_access\"]")
                node.setting("plugins.security.system_indices.enabled", "true")
                if (System.getProperty("resource_sharing.enabled") == "true") {
                    node.setting("plugins.security.experimental.resource_sharing.enabled", "true")
                    node.setting("plugins.security.experimental.resource_sharing.protected_types", "[\"anomaly-detector\", \"forecaster\"]")
                }
            }
        }
    }
}

// Re-write WaitForHttpResource with updated code to support security plugin use case
class WaitForClusterYellow {

    private URL url
    private String username
    private String password
    Set<Integer> validResponseCodes = Collections.singleton(200)

    WaitForClusterYellow(String protocol, String host, int numberOfNodes) throws MalformedURLException {
        this(new URL(protocol + "://" + host + "/_cluster/health?wait_for_nodes=>=" + numberOfNodes + "&wait_for_status=yellow"))
    }

    WaitForClusterYellow(URL url) {
        this.url = url
    }

    boolean wait(int durationInMs) throws GeneralSecurityException, InterruptedException, IOException {
        final long waitUntil = System.nanoTime() + TimeUnit.MILLISECONDS.toNanos(durationInMs)
        final long sleep = 100

        IOException failure = null
        while (true) {
            try {
                checkResource()
                return true
            } catch (IOException e) {
                failure = e
            }
            if (System.nanoTime() < waitUntil) {
                Thread.sleep(sleep)
            } else {
                throw failure
            }
        }
    }

    void setUsername(String username) {
        this.username = username
    }

    void setPassword(String password) {
        this.password = password
    }

    void checkResource() throws IOException {
        final HttpURLConnection connection = buildConnection()
        connection.connect()
        final Integer response = connection.getResponseCode()
        if (validResponseCodes.contains(response)) {
            return
        } else {
            throw new IOException(response + " " + connection.getResponseMessage())
        }
    }

    HttpURLConnection buildConnection() throws IOException {
        final HttpURLConnection connection = (HttpURLConnection) this.@url.openConnection()

        if (connection instanceof HttpsURLConnection) {
            TrustManager[] trustAllCerts = [new X509TrustManager() {
                X509Certificate[] getAcceptedIssuers() {
                    return null
                }

                void checkClientTrusted(X509Certificate[] certs, String authType) {
                }

                void checkServerTrusted(X509Certificate[] certs, String authType) {
                }
            }
            ] as TrustManager[]
            SSLContext sc = SSLContext.getInstance("SSL")
            sc.init(null, trustAllCerts, new java.security.SecureRandom())
            connection.setSSLSocketFactory(sc.getSocketFactory())
            // Create all-trusting host name verifier
            HostnameVerifier allHostsValid = new HostnameVerifier() {
                boolean verify(String hostname, SSLSession session) {
                    return true
                }
            }
            // Install the all-trusting host verifier
            connection.setHostnameVerifier(allHostsValid)
        }

        configureBasicAuth(connection)
        connection.setRequestMethod("GET")
        return connection
    }

    void configureBasicAuth(HttpURLConnection connection) {
        if (username != null) {
            if (password == null) {
                throw new IllegalStateException("Basic Auth user [" + username + "] has been set, but no password has been configured")
            }
            connection.setRequestProperty(
                    "Authorization",
                    "Basic " + Base64.getEncoder().encodeToString((username + ":" + password).getBytes(StandardCharsets.UTF_8))
            )
        }
    }

}

def waitForClusterSetup(OpenSearchCluster cluster, Boolean securityEnabled) {
    cluster.@waitConditions.clear()
    String unicastUris = cluster.nodes.stream().flatMap { node ->
        node.getAllTransportPortURI().stream()
    }.collect(Collectors.joining("\n"))
    cluster.nodes.forEach { node ->
        try {
            Files.write(node.getConfigDir().resolve("unicast_hosts.txt"), unicastUris.getBytes(StandardCharsets.UTF_8))
        } catch (IOException e) {
            throw new java.io.UncheckedIOException("Failed to write configuation files for " + this, e)
        }
    }

    Predicate pred = {
        String protocol = securityEnabled ? "https" : "http"
        String host = System.getProperty("tests.cluster", cluster.getFirstNode().getHttpSocketURI())
        WaitForClusterYellow wait = new WaitForClusterYellow(protocol, host, cluster.nodes.size())
        wait.setUsername(System.getProperty("user", "admin"))
        wait.setPassword(System.getProperty("password", "admin"))
        return wait.wait(180000)
    }

    cluster.@waitConditions.put("cluster health yellow", pred)
    cluster.waitForAllConditions()
}

integTest {
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath
    systemProperty 'buildDir', buildDir.path
    systemProperty "https", System.getProperty("https")
    systemProperty "security", System.getProperty("security")
    systemProperty "user", System.getProperty("user", "admin")
    systemProperty "password", "admin"
    // defaulting to admin since security plugin's demo config tool is not used
    // Tell the test JVM if the cluster JVM is running under a debugger so that tests can use longer timeouts for
    // requests. The 'doFirst' delays reading the debug setting on the cluster till execution time.
    doFirst {
        systemProperty 'cluster.debug', getDebug()
        // Set number of nodes system property to be used in tests
        systemProperty 'cluster.number_of_nodes', "${_numNodes}"
        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
        // not being written, the waitForAllConditions ensures it's written
        getClusters().forEach { cluster ->
            waitForClusterSetup(cluster, securityEnabled)
        }
    }

    // The -Dcluster.debug option makes the cluster debuggable, this makes the tests debuggable
    if (System.getProperty("test.debug") != null) {
        jvmArgs '-agentlib:jdwp=transport=dt_socket,server=n,suspend=y,address=8000'
    }
}

task integTestRemote(type: RestIntegTestTask) {
    testClassesDirs = sourceSets.test.output.classesDirs
    classpath = sourceSets.test.runtimeClasspath
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath

    systemProperty "https", System.getProperty("https")
    systemProperty "user", System.getProperty("user")
    systemProperty "password", System.getProperty("password")

    // Only rest case can run with remote cluster
    if (System.getProperty("tests.rest.cluster") != null) {
        filter {
            includeTestsMatching "org.opensearch.ad.rest.*IT"
            includeTestsMatching "org.opensearch.ad.e2e.*IT"
        }
    }

    if (System.getProperty("https") == null || System.getProperty("https") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.rest.SecureADRestIT"
            excludeTestsMatching "org.opensearch.forecast.rest.SecureForecastRestIT"
        }
    }

    if (System.getProperty("model-benchmark") == null || System.getProperty("model-benchmark") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.*ModelPerfIT"
        }
    }

    if (System.getProperty("long-running") == null || System.getProperty("long-running") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.SingleStreamSmokeIT"
            excludeTestsMatching "org.opensearch.ad.e2e.RealTimeFrequencySmokeIT"
            excludeTestsMatching "org.opensearch.forecast.rest.LongRunningForecastRestApiIT"
        }
    }

    if (System.getProperty("perf") == null || System.getProperty("perf") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.e2e.BatchADSchedulingCheckpointIT"
        }
    }
}

configurations {
    bwcZip
}
dependencies {
    bwcZip "org.opensearch.plugin:opensearch-job-scheduler:${bwcVersion}-SNAPSHOT@zip"
}
ext.resolvebwcZipFile = { pluginId ->
    return new Callable<RegularFile>() {
        @Override
        RegularFile call() throws Exception {
            return new RegularFile() {
                @Override
                File getAsFile() {
                    return configurations.bwcZip.resolvedConfiguration.resolvedArtifacts
                            .find { ResolvedArtifact f ->
                                f.name.startsWith(pluginId)
                            }
                            .file
                }
            }
        }
    }
}
2.times {i ->
    testClusters {
        "${baseName}$i" {
            testDistribution = "ARCHIVE"
            versions = [bwcVersionShort, opensearch_version]
            numberOfNodes = 3
            plugin(provider(resolvebwcZipFile("opensearch-job-scheduler")))
            plugin(provider(new Callable<RegularFile>(){
                @Override
                RegularFile call() throws Exception {
                    return new RegularFile() {
                        @Override
                        File getAsFile() {
                            if (new File("$project.rootDir/$bwcFilePath/anomaly-detection/$bwcVersion").exists()) {
                                project.delete(files("$project.rootDir/$bwcFilePath/anomaly-detection/$bwcVersion"))
                            }
                            project.mkdir bwcAnomalyDetectionPath + bwcVersion
                            ant.get(src: bwcOpenSearchADDownload,
                                    dest: bwcAnomalyDetectionPath + bwcVersion,
                                    httpusecaches: false)
                            return fileTree(bwcAnomalyDetectionPath + bwcVersion).getSingleFile()
                        }
                    }
                }
            }))
            setting 'path.repo', "${buildDir}/cluster/shared/repo/${baseName}"
            setting 'http.content_type.required', 'true'
        }
    }
}

List<Provider<RegularFile>> plugins = []

// Ensure the artifact for the current project version is available to be used for the bwc tests

task prepareBwcTests {
    dependsOn bundlePlugin
    doLast {
        plugins = [
                provider(jobSchedulerFile),
                objects.fileProperty().value(tasks.bundlePlugin.archiveFile)
        ]
    }
}

// Creates 2 test clusters with 3 nodes of the old version.
2.times {i ->
    task "${baseName}#oldVersionClusterTask$i"(type: RestIntegTestTask) {
        dependsOn 'prepareBwcTests'
        useCluster testClusters."${baseName}$i"
        filter {
            includeTestsMatching "org.opensearch.ad.bwc.*IT"
        }
        systemProperty 'tests.rest.bwcsuite', 'old_cluster'
        systemProperty 'tests.rest.bwcsuite_round', 'old'
        systemProperty 'tests.plugin_bwc_version', bwcVersion
        nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}$i".allHttpSocketURI.join(",")}")
        nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}$i".getName()}")
    }
}

// Upgrades one node of the old cluster to new OpenSearch version with upgraded plugin version
// This results in a mixed cluster with 2 nodes on the old version and 1 upgraded node.
// This is also used as a one third upgraded cluster for a rolling upgrade.
task "${baseName}#mixedClusterTask"(type: RestIntegTestTask) {
    useCluster testClusters."${baseName}0"
    dependsOn "${baseName}#oldVersionClusterTask0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'first'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades the second node to new OpenSearch version with upgraded plugin version after the first node is upgraded.
// This results in a mixed cluster with 1 node on the old version and 2 upgraded nodes.
// This is used for rolling upgrade.
task "${baseName}#twoThirdsUpgradedClusterTask"(type: RestIntegTestTask) {
    dependsOn "${baseName}#mixedClusterTask"
    useCluster testClusters."${baseName}0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'second'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades the third node to new OpenSearch version with upgraded plugin version after the second node is upgraded.
// This results in a fully upgraded cluster.
// This is used for rolling upgrade.
task "${baseName}#rollingUpgradeClusterTask"(type: RestIntegTestTask) {
    dependsOn "${baseName}#twoThirdsUpgradedClusterTask"
    useCluster testClusters."${baseName}0"
    doFirst {
      testClusters."${baseName}0".upgradeNodeAndPluginToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    mustRunAfter "${baseName}#mixedClusterTask"
    systemProperty 'tests.rest.bwcsuite', 'mixed_cluster'
    systemProperty 'tests.rest.bwcsuite_round', 'third'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}0".allHttpSocketURI.join(",")}")
    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}0".getName()}")
}

// Upgrades all the nodes of the old cluster to new OpenSearch version with upgraded plugin version
// at the same time resulting in a fully upgraded cluster.
task "${baseName}#fullRestartClusterTask"(type: RestIntegTestTask) {
    dependsOn "${baseName}#oldVersionClusterTask1"
    useCluster testClusters."${baseName}1"
    doFirst {
      testClusters."${baseName}1".upgradeAllNodesAndPluginsToNextVersion(plugins)
    }
    filter {
        includeTestsMatching "org.opensearch.ad.bwc.*IT"
    }
    systemProperty 'tests.rest.bwcsuite', 'upgraded_cluster'
    systemProperty 'tests.plugin_bwc_version', bwcVersion
    nonInputProperties.systemProperty('tests.rest.cluster', "${-> testClusters."${baseName}1".allHttpSocketURI.join(",")}")
    nonInputProperties.systemProperty('tests.clustername', "${-> testClusters."${baseName}1".getName()}")
}

// A bwc test suite which runs all the bwc tasks combined.
task bwcTestSuite(type: RestIntegTestTask) {
    exclude '**/*Test*'
    exclude '**/*IT*'
    dependsOn tasks.named("${baseName}#mixedClusterTask")
    dependsOn tasks.named("${baseName}#rollingUpgradeClusterTask")
    dependsOn tasks.named("${baseName}#fullRestartClusterTask")
}

run {
    doFirst {
        getClusters().forEach { cluster ->
            cluster.waitForAllConditions()
        }

        if (project.hasProperty('dualCluster')) {
            def clusterPorts = [:] // Map to store leader/follow cluster info

            getClusters().forEach { cluster ->
                def clusterName = cluster.getName()
                def allTransportSocketURI = cluster.nodes
                        .collectMany { node -> node.getAllTransportPortURI() }
                        .join(",")

                def allHttpSocketURI = cluster.nodes
                        .collectMany { node -> node.getAllHttpSocketURI() }
                        .join(",")

                clusterPorts[clusterName] = [
                        httpHosts: allHttpSocketURI,
                        transportHosts: allTransportSocketURI
                ]

                println "${clusterName.capitalize()} cluster running at HTTP: ${allHttpSocketURI}, Transport: ${allTransportSocketURI}"
            }

            // Pass cluster info to tests
            if (clusterPorts.containsKey('leader') && clusterPorts.containsKey('follow')) {
                systemProperty "tests.leader.cluster.name", "leader"
                systemProperty "tests.follow.cluster.name", "follower"

                systemProperty "tests.cluster.leader.http_hosts", clusterPorts['leader'].httpHosts
                systemProperty "tests.cluster.follow.http_hosts", clusterPorts['follow'].httpHosts

                systemProperty "tests.cluster.leader.transport_hosts", clusterPorts['leader'].transportHosts
                systemProperty "tests.cluster.follow.transport_hosts", clusterPorts['follow'].transportHosts
            }
        }
    }

    if (project.hasProperty('dualCluster')) {
        useCluster testClusters.leaderCluster
        useCluster testClusters.followCluster
    } else {
        useCluster testClusters.integTest
    }
}


evaluationDependsOnChildren()

task release(type: Copy, group: 'build') {
    dependsOn allprojects*.tasks.build
    from(zipTree(project.tasks.bundlePlugin.outputs.files.getSingleFile()))
    into "build/plugins/opensearch-anomaly-detection"
    includeEmptyDirs = false
    // ES versions < 6.3 have a top-level opensearch directory inside the plugin zip which we need to remove
    eachFile { it.path = it.path - "opensearch/" }
}

def usingRemoteCluster = System.properties.containsKey('tests.rest.cluster') || System.properties.containsKey('tests.cluster')
def usingMultiNode = project.properties.containsKey('numNodes')
// Only apply jacoco test coverage if we are running a local single node cluster
if (!usingRemoteCluster && !usingMultiNode) {
    apply from: 'build-tools/coverage.gradle'
}

List<String> jacocoExclusions = [
        // code for configuration, settings, etc is excluded from coverage
        'org.opensearch.timeseries.TimeSeriesAnalyticsPlugin',

        // rest layer is tested in integration testing mostly, difficult to mock all of it
        'org.opensearch.ad.rest.*',

        // Class containing just constants. Don't need to test
        'org.opensearch.ad.constant.*',
        'org.opensearch.forecast.constant.*',
        'org.opensearch.timeseries.constant.*',
        'org.opensearch.timeseries.settings.TimeSeriesSettings',
        'org.opensearch.forecast.settings.ForecastSettings',

        // related to transport actions added for security
        'org.opensearch.ad.transport.DeleteAnomalyDetectorTransportAction.1',

        // TODO: unified flow caused coverage drop
        'org.opensearch.ad.transport.DeleteAnomalyResultsTransportAction',

        // TODO: add test coverage (kaituo)
        'org.opensearch.forecast.*',
        'org.opensearch.ad.transport.ADHCImputeRequest',
        'org.opensearch.timeseries.transport.BaseDeleteConfigTransportAction.1',
        'org.opensearch.timeseries.transport.BaseSuggestConfigParamTransportAction',
        'org.opensearch.timeseries.rest.AbstractSearchAction.1',
        'org.opensearch.ad.transport.ADSingleStreamResultTransportAction',
        'org.opensearch.timeseries.ratelimit.RateLimitedRequestWorker.RequestQueue',
        'org.opensearch.timeseries.rest.RestStatsAction',
        'org.opensearch.ad.ml.ADCheckpointDao',
        'org.opensearch.timeseries.transport.CronRequest',
        'org.opensearch.ad.task.ADBatchTaskCache',
        'org.opensearch.timeseries.ratelimit.RateLimitedRequestWorker',
        'org.opensearch.timeseries.util.TimeUtil',
        'org.opensearch.ad.transport.ADHCImputeTransportAction',
]


jacocoTestCoverageVerification {
    dependsOn(jacocoTestReport)
    executionData.from = [integTest.jacoco.destinationFile, test.jacoco.destinationFile]
    violationRules {
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'BRANCH'
                minimum = 0.60
            }
        }
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'LINE'
                value = 'COVEREDRATIO'
                minimum = 0.75
            }
        }
    }
}

check.dependsOn jacocoTestCoverageVerification
jacocoTestCoverageVerification.dependsOn jacocoTestReport

compileJava.options.compilerArgs << "-Xlint:-deprecation,-rawtypes,-serial,-try,-unchecked"


// This is afterEvaluate because the bundlePlugin ZIP task is updated afterEvaluate and changes the ZIP name to match the plugin name
afterEvaluate {
    ospackage {
        packageName = "${name}"
        release = isSnapshot ? "0.1" : '1'
        version = "${project.version}" - "-SNAPSHOT"

        into '/usr/share/opensearch/plugins'
        from(zipTree(bundlePlugin.archiveFile)) {
            into opensearchplugin.name
        }

        user = 'root'
        permissionGroup = 'root'
        fileMode = 0644
        dirMode = 0755

        requires('opensearch', versions.opensearch, EQUAL)
        packager = 'Amazon'
        vendor = 'Amazon'
        os = 'LINUX'
        prefix '/usr'
        license = 'ASL-2.0'
        maintainer = 'OpenSearch <opensearch@amazon.com>'
        url = 'https://opensearch.org/downloads.html'
        summary = '''
         Anomaly Detection plugin for OpenSearch.
         Reference documentation can be found at https://opensearch.org/docs/monitoring-plugins/ad/index/.
    '''.stripIndent().replace('\n', ' ').trim()
    }

    buildRpm {
        arch = 'NOARCH'
        dependsOn 'assemble'
        finalizedBy 'renameRpm'
        task renameRpm(type: Copy) {
            from("$buildDir/distributions")
            into("$buildDir/distributions")
            rename "$archiveFileName", "${packageName}-${archiveVersion}.rpm"
            doLast { delete file("$buildDir/distributions/$archiveFileName") }
        }
    }

    buildDeb {
        arch = 'all'
        dependsOn 'assemble'
        finalizedBy 'renameDeb'
        task renameDeb(type: Copy) {
            from("$buildDir/distributions")
            into("$buildDir/distributions")
            rename "$archiveFileName", "${packageName}-${archiveVersion}.deb"
            doLast { delete file("$buildDir/distributions/$archiveFileName") }
        }
    }

    task buildPackages(type: GradleBuild) {
        tasks = ['build', 'buildRpm', 'buildDeb']
    }
}

spotless {
    java {
        removeUnusedImports()
        importOrder 'java', 'javax', 'org', 'com'

        eclipse().configFile rootProject.file('.eclipseformat.xml')
    }
}

// no need to validate pom, as we do not upload to maven/sonatype
validateNebulaPom.enabled = false

tasks.withType(licenseHeaders.class) {
    additionalLicense 'AL   ', 'Apache', 'Licensed under the Apache License, Version 2.0 (the "License")'
}

// show test results so that we can record information like precion/recall results of correctness testing.
if (printLogs) {
    test {
        testLogging {
            showStandardStreams = true
            outputs.upToDateWhen {false}
        }
    }
}

// updateVersion: Task to auto increment to the next development iteration
task updateVersion {
    onlyIf { System.getProperty('newVersion') }
    doLast {
        ext.newVersion = System.getProperty('newVersion')
        println "Setting version to ${newVersion}."
        // String tokenization to support -SNAPSHOT
        // Include the required files that needs to be updated with new Version
        ant.replaceregexp(file:'build.gradle', match: '"opensearch.version", "\\d.*"', replace: '"opensearch.version", "' + newVersion.tokenize('-')[0] + '-SNAPSHOT"', flags:'g', byline:true)
    }
}

// https://github.com/opensearch-project/flow-framework/pull/226
tasks.withType(AbstractPublishToMaven) {
    def predicate = provider {
        publication.name == "pluginZip"
    }
    onlyIf("Publishing only ZIP distributions") {
        predicate.get()
    }
}
