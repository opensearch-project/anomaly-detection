/*
 * SPDX-License-Identifier: Apache-2.0
 *
 * The OpenSearch Contributors require contributions made to
 * this file be licensed under the Apache-2.0 license or a
 * compatible open source license.
 *
 * Modifications Copyright OpenSearch Contributors. See
 * GitHub history for details.
 */

/*
 *   Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *   
 *   Licensed under the Apache License, Version 2.0 (the "License").
 *   You may not use this file except in compliance with the License.
 *   A copy of the License is located at
 *   
 *       http://www.apache.org/licenses/LICENSE-2.0
 *   
 *   or in the "license" file accompanying this file. This file is distributed 
 *   on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either 
 *   express or implied. See the License for the specific language governing 
 *   permissions and limitations under the License.
 */

import java.util.concurrent.Callable
import org.opensearch.gradle.test.RestIntegTestTask

buildscript {
    ext {
        opensearch_group = "org.opensearch"
        opensearch_version = System.getProperty("opensearch.version", "1.0.0")
        common_utils_version = System.getProperty("common_utils.version", "1.0.0.0")
        job_scheduler_version = System.getProperty("job_scheduler.version", "1.0.0.0")
    }

    repositories {
        mavenLocal()
        mavenCentral()
        maven { url "https://plugins.gradle.org/m2/" }
        jcenter()
    }

    dependencies {
        classpath "${opensearch_group}.gradle:build-tools:${opensearch_version}"
    }
}

plugins {
    id 'nebula.ospackage' version "8.3.0" apply false
    id "com.diffplug.gradle.spotless" version "3.26.1"
    id 'java-library'
    id 'checkstyle'
    id "io.freefair.lombok" version "5.1.0"
}

repositories {
    mavenLocal()
    mavenCentral()
    maven { url "https://plugins.gradle.org/m2/" }
    jcenter()
}

ext {
    opensearchVersion = System.getProperty("opensearch.version", "1.0.0")
    isSnapshot = "true" == System.getProperty("build.snapshot", "true")
}

version = "${opensearchVersion}.0"

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'opensearch.opensearchplugin'
apply plugin: 'opensearch.testclusters'
apply plugin: 'base'
apply plugin: 'jacoco'
apply plugin: 'eclipse'

allprojects {
    group = 'org.opensearch'

    plugins.withId('java') {
        sourceCompatibility = targetCompatibility = "1.8"
    }
}

ext {
    projectSubstitutions = [:]
    licenseFile = rootProject.file('LICENSE.txt')
    noticeFile = rootProject.file('NOTICE.txt')
}

opensearchplugin {
    name 'opensearch-anomaly-detection'
    description 'OpenSearch anomaly detector plugin'
    classname 'org.opensearch.ad.AnomalyDetectorPlugin'
    extendedPlugins = ['lang-painless', 'opensearch-job-scheduler']
}

// Handle case where older versions of esplugin doesn't expose the joda time version it uses
configurations.all {
    if (it.state != Configuration.State.UNRESOLVED) return
    resolutionStrategy {
        force "joda-time:joda-time:${versions.joda}"
        force "commons-logging:commons-logging:${versions.commonslogging}"
        force "org.apache.httpcomponents:httpcore:${versions.httpcore}"
        force "commons-codec:commons-codec:${versions.commonscodec}"

        force "org.mockito:mockito-core:3.0.0"
        force "org.objenesis:objenesis:3.0.1"
        force "net.bytebuddy:byte-buddy:1.9.15"
        force "net.bytebuddy:byte-buddy-agent:1.9.15"
        force "com.google.code.gson:gson:2.8.6"
    }
}

configurations {
    testCompile {
        exclude group: 'org.elasticsearch', module: 'securemock'
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
}

tasks.named('forbiddenApisMain').configure {
    // Only enable limited check because AD code has too many violations.
    replaceSignatureFiles 'jdk-signatures'
    signaturesFiles += files('src/forbidden/ad-signatures.txt')
}

tasks.named('forbiddenApisTest').configure {
    // Disable check because AD code has too many violations.
    // For example, we have to allow @Test to be used in test classes not inherited from LuceneTestCase.
    // see https://github.com/elastic/elasticsearch/blob/master/buildSrc/src/main/resources/forbidden/es-test-signatures.txt
    ignoreFailures = true
}

// Allow test cases to be named Tests without having to be inherited from LuceneTestCase.
// see https://github.com/elastic/elasticsearch/blob/323f312bbc829a63056a79ebe45adced5099f6e6/buildSrc/src/main/java/org/elasticsearch/gradle/precommit/TestingConventionsTasks.java
testingConventions.enabled = false

licenseHeaders.enabled = true
dependencyLicenses.enabled = false
thirdPartyAudit.enabled = false
loggerUsageCheck.enabled = false

// See package README.md for details on using these tasks.
def _numNodes = findProperty('numNodes') as Integer ?: 1

def opensearch_tmp_dir = rootProject.file('build/private/opensearch_tmp').absoluteFile
opensearch_tmp_dir.mkdirs()

test {
    include '**/*Tests.class'
    systemProperty 'tests.security.manager', 'false'
}

task integTest(type: RestIntegTestTask) {
    description = "Run tests against a cluster"
    testClassesDirs = sourceSets.test.output.classesDirs
    classpath = sourceSets.test.runtimeClasspath
}
tasks.named("check").configure { dependsOn(integTest) }

integTest {
    dependsOn "bundlePlugin"
    systemProperty 'tests.security.manager', 'false'
    systemProperty 'java.io.tmpdir', opensearch_tmp_dir.absolutePath

    systemProperty "https", System.getProperty("https")
    systemProperty "user", System.getProperty("user")
    systemProperty "password", System.getProperty("password")

    // Only rest case can run with remote cluster
    if (System.getProperty("tests.rest.cluster") != null) {
        filter {
            includeTestsMatching "org.opensearch.ad.rest.*IT"
            includeTestsMatching "org.opensearch.ad.e2e.*IT"
        }
    }

    if (System.getProperty("https") == null || System.getProperty("https") == "false") {
        filter {
            excludeTestsMatching "org.opensearch.ad.rest.SecureADRestIT"
        }
    }

    // The 'doFirst' delays till execution time.
    doFirst {
        // Tell the test JVM if the cluster JVM is running under a debugger so that tests can
        // use longer timeouts for requests.
        def isDebuggingCluster = getDebug() || System.getProperty("test.debug") != null
        systemProperty 'cluster.debug', isDebuggingCluster
        // Set number of nodes system property to be used in tests
        systemProperty 'cluster.number_of_nodes', "${_numNodes}"
        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
        // not being written, the waitForAllConditions ensures it's written
        getClusters().forEach { cluster ->
            cluster.waitForAllConditions()
        }
    }

    // The --debug-jvm command-line option makes the cluster debuggable; this makes the tests debuggable
    if (System.getProperty("test.debug") != null) {
        jvmArgs '-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=*:5005'
    }

}

testClusters.integTest {
    testDistribution = "ARCHIVE"
    // Cluster shrink exception thrown if we try to set numberOfNodes to 1, so only apply if > 1
    if (_numNodes > 1) numberOfNodes = _numNodes
    // When running integration tests it doesn't forward the --debug-jvm to the cluster anymore
    // i.e. we have to use a custom property to flag when we want to debug elasticsearch JVM
    // since we also support multi node integration tests we increase debugPort per node
    if (System.getProperty("opensearch.debug") != null) {
        def debugPort = 5005
        nodes.forEach { node ->
            node.jvmArgs("-agentlib:jdwp=transport=dt_socket,server=n,suspend=y,address=*:${debugPort}")
            debugPort += 1
        }
    }
    plugin(project.tasks.bundlePlugin.archiveFile)

    plugin(provider(new Callable<RegularFile>(){
        @Override
        RegularFile call() throws Exception {
            return new RegularFile() {
                @Override
                File getAsFile() {
                    return fileTree("src/test/resources/job-scheduler").getSingleFile()
                }
            }
        }
    }))

    // As of ES 7.7.0 the opendistro-anomaly-detection plugin is being added to the list of plugins for the testCluster during build before
    // the opensearch-job-scheduler plugin, which is causing build failures. From the stack trace, this looks like a bug.
    //
    // Exception in thread "main" java.lang.IllegalArgumentException: Missing plugin [opensearch-job-scheduler], dependency of [opendistro-anomaly-detection]
    //       at org.opensearch.plugins.PluginsService.addSortedBundle(PluginsService.java:452)
    //
    // One explanation is that ES build script sort plugins according to the natural ordering of their names.
    // opendistro-anomaly-detection comes before opensearch-job-scheduler.
    //
    // The following is a comparison of different plugin installation order:
    // Before 7.7:
    // ./bin/elasticsearch-plugin install --batch file:opendistro-anomaly-detection.zip file:opensearch-job-scheduler.zip
    //
    // After 7.7:
    // ./bin/elasticsearch-plugin install --batch file:opensearch-job-scheduler.zip file:opendistro-anomaly-detection.zip
    //
    // A temporary hack is to reorder the plugins list after evaluation but prior to task execution when the plugins are installed.
    nodes.each { node ->
        def plugins = node.plugins
        def firstPlugin = plugins.get(0)
        plugins.remove(0)
        plugins.add(firstPlugin)
    }
}

run {
    doFirst {
        // There seems to be an issue when running multi node run or integ tasks with unicast_hosts
        // not being written, the waitForAllConditions ensures it's written
        getClusters().forEach { cluster ->
            cluster.waitForAllConditions()
        }
    }

    useCluster testClusters.integTest
}

evaluationDependsOnChildren()

task release(type: Copy, group: 'build') {
    dependsOn allprojects*.tasks.build
    from(zipTree(project.tasks.bundlePlugin.outputs.files.getSingleFile()))
    into "build/plugins/opensearch-anomaly-detection"
    includeEmptyDirs = false
    // ES versions < 6.3 have a top-level opensearch directory inside the plugin zip which we need to remove
    eachFile { it.path = it.path - "opensearch/" }
}

List<String> jacocoExclusions = [
        // code for configuration, settings, etc is excluded from coverage
        'org.opensearch.ad.AnomalyDetectorPlugin',
        'org.opensearch.ad.settings.AnomalyDetectorSettings',

        //TODO: add more test cases later for these package
        'org.opensearch.ad.model.*',
        'org.opensearch.ad.rest.*',
        'org.opensearch.ad.transport.handler.DetectionStateHandler',
        'org.opensearch.ad.AnomalyDetectorJobRunner',

        // Class containing just constants.  Don't need to test
        'org.opensearch.ad.constant.*',

        // mostly skeleton code.  Tested major logic in restful api tests
        'org.opensearch.ad.settings.EnabledSetting',

        'org.opensearch.ad.common.exception.FeatureNotAvailableException',
        'org.opensearch.ad.common.exception.AnomalyDetectionException',
        'org.opensearch.ad.util.ClientUtil',

        'org.opensearch.ad.transport.StopDetectorRequest',
        'org.opensearch.ad.transport.StopDetectorResponse',
        'org.opensearch.ad.transport.StopDetectorTransportAction',
        'org.opensearch.ad.transport.DeleteDetectorAction',
        'org.opensearch.ad.transport.CronTransportAction',
        'org.opensearch.ad.transport.CronRequest',
        'org.opensearch.ad.transport.ADStatsNodesAction',
        'org.opensearch.ad.AnomalyDetectorRunner',
        'org.opensearch.ad.util.ParseUtils',

        // related to transport actions added for security
        'org.opensearch.ad.transport.StatsAnomalyDetectorTransportAction',
        'org.opensearch.ad.transport.DeleteAnomalyDetectorTransportAction*',
        'org.opensearch.ad.transport.SearchAnomalyDetectorTransportAction*',
        'org.opensearch.ad.transport.GetAnomalyDetectorTransportAction*',
        'org.opensearch.ad.transport.SearchAnomalyResultTransportAction*',
        'org.opensearch.ad.transport.SearchAnomalyDetectorInfoTransportAction*',

        // TODO: hc caused coverage to drop
        'org.opensearch.ad.indices.AnomalyDetectionIndices',
        'org.opensearch.ad.transport.handler.MultiEntityResultHandler',
        'org.opensearch.ad.util.ThrowingSupplierWrapper',
        'org.opensearch.ad.transport.ProfileNodeResponse',
        'org.opensearch.ad.transport.ADResultBulkResponse',
        'org.opensearch.ad.transport.AggregationType',
        'org.opensearch.ad.EntityProfileRunner',
        'org.opensearch.ad.NodeStateManager',
        'org.opensearch.ad.util.BulkUtil',
        'org.opensearch.ad.util.ExceptionUtil',
        'org.opensearch.ad.ml.EntityModel',
        'org.opensearch.ad.ml.ModelPartitioner',

        // TODO: unified flow caused coverage drop
        'org.opensearch.ad.transport.AnomalyDetectorJobRequest',
        'org.opensearch.ad.transport.ADTaskProfileTransportAction',
        'org.opensearch.ad.transport.ADCancelTaskRequest',
        'org.opensearch.ad.transport.ADTaskProfileNodeRequest',
        'org.opensearch.ad.transport.ADCancelTaskTransportAction',
        'org.opensearch.ad.transport.ADTaskProfileRequest',
        'org.opensearch.ad.transport.ADCancelTaskNodeRequest',
        'org.opensearch.ad.task.ADTaskManager',
        'org.opensearch.ad.transport.ForwardADTaskTransportAction',
        'org.opensearch.ad.task.ADHCBatchTaskCache',
        'org.opensearch.ad.task.ADBatchTaskRunner',
        'org.opensearch.ad.transport.ForwardADTaskRequest',
        'org.opensearch.ad.task.ADBatchTaskCache',
        'org.opensearch.ad.transport.ADBatchAnomalyResultResponse',
        'org.opensearch.ad.transport.AnomalyDetectorJobTransportAction',
        'org.opensearch.ad.transport.CronNodeRequest',
        'org.opensearch.ad.transport.DeleteAnomalyResultsTransportAction',
        'org.opensearch.ad.transport.GetAnomalyDetectorResponse'

        // TODO: until ercf move to rcf repo,
        ,'com.amazon.randomcutforest.*'
]

jacocoTestCoverageVerification {
    violationRules {
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'BRANCH'
                minimum = 0.60
            }
        }
        rule {
            element = 'CLASS'
            excludes = jacocoExclusions
            limit {
                counter = 'LINE'
                value = 'COVEREDRATIO'
                minimum = 0.75
            }
        }
    }
}

jacocoTestReport {
    reports {
        xml.enabled = true
        html.enabled = true
    }
}

check.dependsOn jacocoTestCoverageVerification
jacocoTestCoverageVerification.dependsOn jacocoTestReport

checkstyle {
    toolVersion = '8.29'
}

dependencies {
    compile "org.opensearch:opensearch:${opensearch_version}"
    compileOnly "org.opensearch.plugin:opensearch-scripting-painless-spi:${opensearch_version}"
    compileOnly "org.opensearch:opensearch-job-scheduler-spi:${job_scheduler_version}"
    compile "org.opensearch:common-utils:${common_utils_version}"
    compile "org.opensearch.client:opensearch-rest-client:${opensearch_version}"
    compile group: 'com.google.guava', name: 'guava', version:'29.0-jre'
    compile group: 'org.apache.commons', name: 'commons-math3', version: '3.6.1'
    compile group: 'com.google.code.gson', name: 'gson', version: '2.8.6'
    compile group: 'com.yahoo.datasketches', name: 'sketches-core', version: '0.13.4'
    compile group: 'com.yahoo.datasketches', name: 'memory', version: '0.12.2'
    compile group: 'commons-lang', name: 'commons-lang', version: '2.6'
    compile group: 'org.apache.commons', name: 'commons-pool2', version: '2.10.0'

    // randomcutforest-serialization uses jackson 2.12, but opensearch-scripting-painless-spi uses jackson 2.11.
    // compile scope won't work due to conflict.
    // resolutionStrategy using 2.11 won't work as 
    // com.fasterxml.jackson.databind.ObjectMapper depends on com/fasterxml/jackson/core/util/JacksonFeature
    // that is created since 2.12. Compile won't fail but there is a runtime ClassNotFoundException
    // due to absent JacksonFeature.
    // The fix is to put jackson in direct dependency and use implementation scope.
    // implementation scope let the dependency in both compiling and running classpath, but
    // not leaked through to clients (Opensearch). Here we force the jackson version to whatever
    // opensearch uses.
    compile 'software.amazon.randomcutforest:randomcutforest-core:2.0-rc2'
    implementation 'software.amazon.randomcutforest:randomcutforest-serialization:2.0-rc2'
    implementation "com.fasterxml.jackson.core:jackson-core:${versions.jackson}"
    implementation "com.fasterxml.jackson.core:jackson-databind:${versions.jackson}"
    implementation "com.fasterxml.jackson.core:jackson-annotations:${versions.jackson}"

    // used for serializing/deserializing rcf models.
    compile group: 'io.protostuff', name: 'protostuff-core', version: '1.7.4'
    compile group: 'io.protostuff', name: 'protostuff-runtime', version: '1.7.4'

    compile "org.jacoco:org.jacoco.agent:0.8.5"
    compile ("org.jacoco:org.jacoco.ant:0.8.5") {
        exclude group: 'org.ow2.asm', module: 'asm-commons'
        exclude group: 'org.ow2.asm', module: 'asm'
        exclude group: 'org.ow2.asm', module: 'asm-tree'
    }

    testCompile group: 'pl.pragmatists', name: 'JUnitParams', version: '1.1.1'
    testImplementation group: 'org.mockito', name: 'mockito-core', version: '3.0.0'
    testImplementation group: 'org.powermock', name: 'powermock-api-mockito2', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-module-junit4', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-module-junit4-common', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-core', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-api-support', version: '2.0.2'
    testImplementation group: 'org.powermock', name: 'powermock-reflect', version: '2.0.7'
    testImplementation group: 'org.objenesis', name: 'objenesis', version: '3.0.1'
    testImplementation group: 'org.javassist', name: 'javassist', version: '3.27.0-GA'
    testCompile group: 'net.bytebuddy', name: 'byte-buddy', version: '1.9.15'
    testCompile group: 'net.bytebuddy', name: 'byte-buddy-agent', version: '1.9.15'

    checkstyle "com.puppycrawl.tools:checkstyle:${project.checkstyle.toolVersion}"
}

compileJava.options.compilerArgs << "-Xlint:-deprecation,-rawtypes,-serial,-try,-unchecked"
compileJava {
    options.compilerArgs.addAll(["-processor", 'lombok.launch.AnnotationProcessorHider$AnnotationProcessor'])
}

apply plugin: 'nebula.ospackage'

// This is afterEvaluate because the bundlePlugin ZIP task is updated afterEvaluate and changes the ZIP name to match the plugin name
afterEvaluate {
    ospackage {
        packageName = "${name}"
        release = isSnapshot ? "0.1" : '1'
        version = "${project.version}" - "-SNAPSHOT"

        into '/usr/share/opensearch/plugins'
        from(zipTree(bundlePlugin.archivePath)) {
            into opensearchplugin.name
        }

        user 'root'
        permissionGroup 'root'
        fileMode 0644
        dirMode 0755

        requires('opensearch-oss', versions.opensearch, EQUAL)
        packager = 'Amazon'
        vendor = 'Amazon'
        os = 'LINUX'
        prefix '/usr'

        license 'ASL-2.0'
        maintainer 'OpenSearch <opensearch@amazon.com>'
        url 'https://opensearch.org/downloads.html'
        summary '''
         Anomaly Detection plugin for OpenSearch.
         Reference documentation can be found at https://opensearch.org/docs/monitoring-plugins/ad/index/.
    '''.stripIndent().replace('\n', ' ').trim()
    }

    buildRpm {
        arch = 'NOARCH'
        dependsOn 'assemble'
        finalizedBy 'renameRpm'
        task renameRpm(type: Copy) {
            from("$buildDir/distributions")
            into("$buildDir/distributions")
            include archiveName
            rename archiveName, "${packageName}-${version}.rpm"
            doLast { delete file("$buildDir/distributions/$archiveName") }
        }
    }

    buildDeb {
        arch = 'all'
        dependsOn 'assemble'
        finalizedBy 'renameDeb'
        task renameDeb(type: Copy) {
            from("$buildDir/distributions")
            into("$buildDir/distributions")
            include archiveName
            rename archiveName, "${packageName}-${version}.deb"
            doLast { delete file("$buildDir/distributions/$archiveName") }
        }
    }

    task buildPackages(type: GradleBuild) {
        tasks = ['build', 'buildRpm', 'buildDeb']
    }
}

spotless {
    java {
        removeUnusedImports()
        importOrder 'java', 'javax', 'org', 'com'

        eclipse().configFile rootProject.file('.eclipseformat.xml')
    }
}

// no need to validate pom, as we do not upload to maven/sonatype
validateNebulaPom.enabled = false

tasks.withType(licenseHeaders.class) {
    additionalLicense 'AL   ', 'Apache', 'Licensed under the Apache License, Version 2.0 (the "License")'
}
